# Test Design: Story 3.2 - Stage 4 Brand Contextualization

**Date:** 2025-10-07
**Designer:** Quinn (Test Architect)
**Story:** Epic 3, Story 3.2 - Stage 4 Brand Research and Contextualization Chain

---

## Test Strategy Overview

- **Total test scenarios:** 22
- **Unit tests:** 7 (32%)
- **Integration tests:** 11 (50%)
- **E2E tests:** 4 (18%)
- **Priority distribution:** P0: 13, P1: 7, P2: 2

**Strategy Rationale:**
Stage 4 is identified as the "critical differentiation layer" where quality determines business value. Heavy emphasis on integration testing reflects the multi-source data integration complexity (brand profile YAML + research markdown + Stage 3 output). E2E tests validate the complete contextualization workflow quality.

---

## Test Scenarios by Acceptance Criteria

### AC1: File Structure and Class Implementation

**Requirement:** `pipeline/stages/stage4_brand_contextualization.py` with `Stage4Chain` class exists

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-UNIT-001 | Unit | P1 | Verify Stage4Chain class exists and implements required interface | Structural validation |
| 3.2-UNIT-002 | Unit | P1 | Verify Stage4Chain initializes with required parameters (llm, prompt, output_parser) | Constructor validation |

---

### AC2: Brand Profile Loading

**Requirement:** Brand profile loaded from YAML using `load_brand_profile(brand_id)` helper

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-UNIT-003 | Unit | P0 | Verify load_brand_profile returns dict with required fields (name, industry, positioning) | Data structure validation |
| 3.2-INT-001 | Integration | P0 | Load valid brand profile YAML (e.g., lactalis.yaml) and verify all fields parsed correctly | File I/O + parsing |
| 3.2-INT-002 | Integration | P0 | Test load_brand_profile with missing brand_id raises appropriate error | Error handling for invalid input |
| 3.2-INT-003 | Integration | P1 | Test load_brand_profile with malformed YAML handles error gracefully | Data corruption resilience |

---

### AC3: Brand Research Data Retrieval

**Requirement:** Research data retrieved using `get_brand_research(brand_name)` from `docs/web-search-setup/`

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-UNIT-004 | Unit | P0 | Verify get_brand_research constructs correct file path from brand_name | Path logic validation |
| 3.2-INT-004 | Integration | P0 | Load valid research markdown and verify content sections present | File I/O + content validation |
| 3.2-INT-005 | Integration | P0 | Test get_brand_research with missing research file returns None (graceful degradation per AC9) | Error handling |
| 3.2-INT-006 | Integration | P1 | Verify get_brand_research handles large research files (35-48KB per dev notes) | Performance validation |
| 3.2-INT-007 | Integration | P1 | Test get_brand_research with empty research file handles gracefully | Edge case |

---

### AC4: Prompt Template Configuration

**Requirement:** PromptTemplate in `pipeline/prompts/stage4_prompt.py` with brand customization instructions

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-UNIT-005 | Unit | P0 | Verify prompt template contains all required input variables (brand_profile, research_data, universal_lessons) | Template structure |
| 3.2-INT-008 | Integration | P0 | Inject brand profile into prompt and verify proper substitution | Template rendering |
| 3.2-INT-009 | Integration | P0 | Inject research data into prompt and verify content included without truncation | Data injection validation |
| 3.2-INT-010 | Integration | P1 | Test prompt generation with missing research data (graceful degradation) | Error handling |

---

### AC5: LLM Configuration

**Requirement:** ChatOpenAI with OpenRouter (Claude Sonnet 4.5), temperature=0.5

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-UNIT-006 | Unit | P1 | Verify LLM initialized with correct model_name (claude-3.5-sonnet per dev notes) | Configuration validation |
| 3.2-UNIT-007 | Unit | P1 | Verify LLM temperature set to 0.5 | Configuration validation |

---

### AC6: Output Format

**Requirement:** Structured markdown with "Brand Context Summary" and "Brand-Specific Strategic Insights"

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-INT-011 | Integration | P0 | Verify output contains "Brand Context Summary" section | Output structure validation |
| 3.2-E2E-001 | E2E | P0 | Run Stage 4 and verify "Brand-Specific Strategic Insights" contains 5-7 numbered items | Quality validation |
| 3.2-E2E-002 | E2E | P0 | Verify insights reference brand-specific context (product names, customer segments) | Contextualization quality |

---

### AC7: Pipeline Integration

**Requirement:** Stage 4 integrated into `run_pipeline.py` with output saved to `stage4/brand-contextualization.md`

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-INT-012 | Integration | P0 | Verify Stage 4 receives Stage 3 output correctly | Data flow validation |
| 3.2-INT-013 | Integration | P0 | Verify output file written to correct path (stage4/brand-contextualization.md) | File I/O |
| 3.2-INT-014 | Integration | P1 | Test Stage 4 execution logs appropriate info/debug messages | Observability |

---

### AC8: Full Pipeline Test Execution

**Requirement:** Run Stages 1-3-4 on Savannah Bananas → Lactalis, verify dairy-specific insights

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-E2E-003 | E2E | P0 | Execute full pipeline (Stages 1-4) with Savannah Bananas input → Lactalis brand | Critical user journey |
| 3.2-E2E-004 | E2E | P0 | Verify output references Lactalis-specific products (Cracker Barrel, Black Diamond, lactose-free) | Quality validation per AC8 |

---

### AC9: Graceful Degradation

**Requirement:** If research data missing, proceed with brand profile only and log warning

#### Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 3.2-INT-015 | Integration | P0 | Run Stage 4 with missing research data, verify execution completes | Resilience testing |
| 3.2-INT-016 | Integration | P0 | Verify warning logged when research data unavailable | Error observability |
| 3.2-INT-017 | Integration | P2 | Verify degraded output still generates insights (lower quality acceptable) | Degraded functionality |

---

## Risk Coverage

**Identified Risks:**

1. **RISK-001: Poor Contextualization Quality** (High Impact)
   - Mitigated by: 3.2-E2E-001, 3.2-E2E-002, 3.2-E2E-004
   - Multi-level validation of insight quality and brand-specificity

2. **RISK-002: Data Loading Failures** (Medium Impact)
   - Mitigated by: 3.2-INT-001, 3.2-INT-002, 3.2-INT-004, 3.2-INT-005
   - Comprehensive error handling coverage

3. **RISK-003: Pipeline Integration Issues** (High Impact)
   - Mitigated by: 3.2-INT-012, 3.2-E2E-003
   - Data flow validation across stages

4. **RISK-004: Graceful Degradation Failure** (Medium Impact)
   - Mitigated by: 3.2-INT-015, 3.2-INT-016, 3.2-INT-017
   - Explicit degradation scenario testing

---

## Test Level Justification Summary

**Unit Tests (32%):**
- Pure logic validation: path construction, configuration values, data structure validation
- Fast feedback for business logic errors
- No external dependencies

**Integration Tests (50%):**
- File I/O operations (YAML loading, markdown reading)
- Data injection and template rendering
- Multi-component interactions (Stage 3 → Stage 4 data flow)
- Error handling with external dependencies

**E2E Tests (18%):**
- Critical path validation: Full pipeline execution
- Quality validation: Brand-specific insight verification
- Realistic scenario testing per AC8 requirements
- Higher ratio justified by "critical differentiation layer" status

---

## Recommended Execution Order

### Phase 1: Fast Feedback (Unit Tests)
1. 3.2-UNIT-001 through 3.2-UNIT-007 (all P0/P1 unit tests)
   - **Duration:** ~30 seconds
   - **Fail fast:** Catch structural and configuration issues immediately

### Phase 2: Integration Validation (P0 Integration)
2. 3.2-INT-001, 3.2-INT-002 (brand profile loading)
3. 3.2-INT-004, 3.2-INT-005 (research data retrieval)
4. 3.2-INT-008, 3.2-INT-009 (prompt injection)
5. 3.2-INT-011, 3.2-INT-012, 3.2-INT-013 (output and pipeline)
6. 3.2-INT-015, 3.2-INT-016 (graceful degradation)
   - **Duration:** ~2-3 minutes
   - **Critical path:** Validate all data flows before E2E

### Phase 3: End-to-End Quality Validation (P0 E2E)
7. 3.2-E2E-003 (full pipeline execution)
8. 3.2-E2E-001, 3.2-E2E-002, 3.2-E2E-004 (output quality)
   - **Duration:** ~5-10 minutes (LLM calls)
   - **Quality gate:** Final validation of contextualization quality

### Phase 4: Secondary Coverage (P1/P2)
9. Remaining P1 integration tests
10. P2 degraded functionality test
   - **Duration:** ~2-3 minutes
   - **Best effort:** Run when time permits

**Total estimated test suite duration:** 10-20 minutes (dominated by LLM inference time in E2E tests)

---

## Coverage Validation

✅ **All acceptance criteria covered:**
- AC1: 2 scenarios (UNIT-001, UNIT-002)
- AC2: 4 scenarios (UNIT-003, INT-001, INT-002, INT-003)
- AC3: 5 scenarios (UNIT-004, INT-004, INT-005, INT-006, INT-007)
- AC4: 4 scenarios (UNIT-005, INT-008, INT-009, INT-010)
- AC5: 2 scenarios (UNIT-006, UNIT-007)
- AC6: 3 scenarios (INT-011, E2E-001, E2E-002)
- AC7: 3 scenarios (INT-012, INT-013, INT-014)
- AC8: 2 scenarios (E2E-003, E2E-004)
- AC9: 3 scenarios (INT-015, INT-016, INT-017)

✅ **No duplicate coverage across levels** - Each scenario tests distinct aspects

✅ **Critical paths have defense in depth:**
- Brand profile loading: Unit + Integration (3 levels)
- Research data retrieval: Unit + Integration (3 levels)
- Full pipeline: Integration + E2E (2 levels)

✅ **All P0 risks mitigated** with explicit test coverage

---

## Quality Checklist

- [x] Every AC has test coverage (28 scenarios across 9 ACs)
- [x] Test levels are appropriate (shift-left applied: 32% unit, 50% integration)
- [x] No duplicate coverage across levels (verified per scenario)
- [x] Priorities align with business risk (Stage 4 = critical differentiation → 13 P0 tests)
- [x] Test IDs follow naming convention (3.2-{LEVEL}-{SEQ})
- [x] Scenarios are atomic and independent (each tests single aspect)

---

## Implementation Notes

**Test Framework Recommendations:**
- **Unit tests:** pytest with mocking for file I/O
- **Integration tests:** pytest with test fixtures for sample YAML/markdown files
- **E2E tests:** Full pipeline execution with real LLM calls (use test brand profiles)

**Test Data Requirements:**
- Sample brand profile YAML (valid, malformed, missing)
- Sample research markdown (valid, empty, large 48KB file)
- Sample Stage 3 output (universal lessons)
- Expected output templates for validation

**Continuous Monitoring:**
- Track E2E test LLM response quality over time (insight count, brand-specificity)
- Monitor graceful degradation path usage in production
- Alert on contextualization quality regressions

---

## Gate YAML Block

```yaml
test_design:
  scenarios_total: 22
  by_level:
    unit: 7
    integration: 11
    e2e: 4
  by_priority:
    p0: 13
    p1: 7
    p2: 2
    p3: 0
  coverage_gaps: []
  risk_coverage:
    - RISK-001: Poor Contextualization Quality (3 E2E tests)
    - RISK-002: Data Loading Failures (4 integration tests)
    - RISK-003: Pipeline Integration Issues (2 tests)
    - RISK-004: Graceful Degradation Failure (3 tests)
  estimated_duration: "10-20 minutes"
  critical_notes:
    - Stage 4 critical differentiation layer requires high test coverage
    - E2E tests validate contextualization quality (business value driver)
    - Graceful degradation must be tested explicitly per AC9
```

---

## Trace References

For use by trace-requirements task:

```
Test design matrix: docs/qa/assessments/3.2-test-design-20251007.md
P0 tests identified: 13
Total scenarios: 22
Coverage: 9/9 acceptance criteria (100%)
```

---

**Assessment:** Comprehensive test strategy with appropriate level distribution. Heavy integration focus reflects multi-source data complexity. P0 priority concentration (59%) aligns with Stage 4's "critical differentiation" status. Graceful degradation explicitly tested per requirements.

**Recommendation:** APPROVED for implementation. Execute tests in recommended order for fast feedback and efficient debugging.
