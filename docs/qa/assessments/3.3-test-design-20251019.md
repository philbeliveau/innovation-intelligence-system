# Test Design: Story 3.3 - Status Polling and Monitoring

**Date:** 2025-10-19
**Designer:** Quinn (Test Architect)
**Story:** 3.3 - Status Polling and Monitoring
**Status:** Ready for Implementation

---

## Test Strategy Overview

- **Total test scenarios:** 24
- **Unit tests:** 8 (33%)
- **Integration tests:** 9 (38%)
- **E2E tests:** 7 (29%)
- **Priority distribution:** P0: 10, P1: 10, P2: 4

### Rationale

This feature has **high user visibility** (real-time pipeline monitoring is the core UX) and **high technical risk** (polling/cleanup bugs = memory leaks). The distribution reflects:

- **Unit tests (33%):** Component logic and status calculations
- **Integration tests (38%):** API integration, polling behavior, state management
- **E2E tests (29%):** Critical user journey validation (upload → monitor → results)

---

## Test Scenarios by Acceptance Criteria

### AC1: Pipeline viewer page polls `/api/status/[runId]` every 5 seconds

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-001  | Integration | P0       | Polling starts immediately on mount        | Core polling behavior - critical to user experience|
| 3.3-INT-002  | Integration | P0       | Polling interval is exactly 5000ms         | Ensures correct timing - prevent server overload   |
| 3.3-INT-003  | Integration | P1       | Polling sends correct runId in URL path    | Validates API integration contract                 |
| 3.3-E2E-001  | E2E         | P1       | Browser network tab shows polling calls    | User-observable network behavior                   |

**Risk Coverage:** Mitigates RISK-001 (polling not starting), RISK-002 (wrong interval)

---

### AC2: On mount, page immediately fetches initial status and continues polling until status is "complete" or "error"

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-004  | Integration | P0       | Initial fetch occurs before first interval | Critical UX - immediate feedback required          |
| 3.3-INT-005  | Integration | P0       | Polling stops when status="complete"       | Prevent unnecessary server load                    |
| 3.3-INT-006  | Integration | P0       | Polling stops when status="error"          | Prevent error-state polling loop                   |
| 3.3-E2E-002  | E2E         | P1       | E2E: Upload → Pipeline completes → No polls| Validates complete user journey with polling stop  |

**Risk Coverage:** Mitigates RISK-003 (infinite polling), RISK-004 (no initial data)

---

### AC3: Display vertical column of 5 stage boxes flowing downward showing stage number, short name, and status icon

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-UNIT-001 | Unit        | P1       | StageBox renders stage number correctly    | Pure component logic - isolated test               |
| 3.3-UNIT-002 | Unit        | P1       | StageBox renders stage name correctly      | Pure component logic - isolated test               |
| 3.3-UNIT-003 | Unit        | P1       | StageBox displays correct icon for status  | Status icon mapping - pure logic                   |
| 3.3-INT-007  | Integration | P2       | All 5 stage boxes render in vertical order | Component composition and layout                   |

**Risk Coverage:** Mitigates RISK-005 (incorrect stage display)

---

### AC4: Active stage (current_stage) is highlighted with border and pulse animation

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-UNIT-004 | Unit        | P1       | StageBox applies 'running' styles          | CSS class application logic                        |
| 3.3-INT-008  | Integration | P1       | Active stage updates when API returns new  | State propagation from API to UI                   |
| 3.3-E2E-003  | E2E         | P2       | Visual regression: pulse animation visible | User-perceivable animation behavior                |

**Risk Coverage:** Mitigates RISK-006 (no visual feedback on active stage)

---

### AC5: Completed stages (< current_stage) show green checkmark, pending stages (> current_stage) are grayed out

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-UNIT-005 | Unit        | P0       | Status calculation: stage < current → 'completed' | Business logic for status determination         |
| 3.3-UNIT-006 | Unit        | P0       | Status calculation: stage > current → 'pending'   | Business logic for status determination         |
| 3.3-UNIT-007 | Unit        | P0       | Status calculation: stage = current → 'running'   | Business logic for status determination         |
| 3.3-E2E-004  | E2E         | P1       | E2E: Stage progression shows correct icons | Visual validation of complete workflow             |

**Risk Coverage:** Mitigates RISK-007 (incorrect status display logic)

---

### AC6: When `current_stage >= 1` and `stage1_data` exists, display 2 track cards side-by-side

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-UNIT-008 | Unit        | P1       | TrackCard renders with correct props       | Component rendering logic                          |
| 3.3-INT-009  | Integration | P0       | Track cards display when stage1_data present| API data → UI rendering integration               |
| 3.3-INT-010  | Integration | P0       | Track cards hidden when stage1_data null   | Conditional rendering logic                        |
| 3.3-E2E-005  | E2E         | P1       | E2E: Track cards appear after Stage 1      | User-observable feature behavior                   |

**Risk Coverage:** Mitigates RISK-008 (premature track display)

---

### AC7: Track cards show title, summary, and "Selected" badge with checkmark

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-011  | Integration | P1       | TrackCard displays all required fields     | Component integration with shadcn/ui Badge         |
| 3.3-E2E-006  | E2E         | P2       | Visual regression: badge styling correct   | User-facing visual consistency                     |

**Risk Coverage:** Mitigates RISK-009 (missing track card fields)

---

### AC8: Display current stage detail panel below stage boxes with stage description and status message

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-012  | Integration | P1       | DetailPanel shows correct stage description| State → UI integration                             |
| 3.3-INT-013  | Integration | P1       | DetailPanel updates on stage change        | React state propagation                            |

**Risk Coverage:** Mitigates RISK-010 (stale detail panel)

---

### AC9: When `status === "complete"`, show "View Opportunities →" button that redirects to `/results/[runId]`

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-014  | Integration | P0       | Button appears when status="complete"      | Conditional rendering critical to user flow        |
| 3.3-INT-015  | Integration | P0       | Button click navigates to /results/[runId] | Navigation integration (Next.js router)            |
| 3.3-E2E-007  | E2E         | P0       | E2E: Complete pipeline → Click button → Results page | Critical user journey exit path            |

**Risk Coverage:** Mitigates RISK-011 (user stuck on pipeline page)

---

### AC10: Polling cleanup: Clear setTimeout on component unmount to prevent memory leaks

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-016  | Integration | P0       | useEffect cleanup clears timeout           | Memory leak prevention - CRITICAL                  |
| 3.3-INT-017  | Integration | P0       | No timeouts remain after unmount           | Verify cleanup with React DevTools                 |

**Risk Coverage:** Mitigates RISK-012 (memory leaks from polling)

**PRIORITY RATIONALE:** P0 because memory leaks can degrade browser performance and crash tabs in long sessions.

---

### AC11: Error handling: Display "Pipeline not found" for 404, "Pipeline failed" for error status, network retry once then show error

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-018  | Integration | P1       | 404 response displays "Pipeline not found" | Error state handling                               |
| 3.3-INT-019  | Integration | P1       | Error status displays "Pipeline failed"    | Error state handling                               |
| 3.3-INT-020  | Integration | P0       | Network error retries once before failing  | Resilience to transient network issues             |
| 3.3-INT-021  | Integration | P1       | Polling stops after error                  | Prevent infinite error polling                     |

**Risk Coverage:** Mitigates RISK-013 (poor error UX), RISK-014 (network failure loops)

---

### AC12: Loading states: Show skeleton loaders for tracks while Stage 1 is running

#### Scenarios

| ID           | Level       | Priority | Test                                       | Justification                                      |
| ------------ | ----------- | -------- | ------------------------------------------ | -------------------------------------------------- |
| 3.3-INT-022  | Integration | P2       | Skeleton shown when currentStage=1 and stage1_data=null | Loading state logic                    |
| 3.3-INT-023  | Integration | P2       | Skeleton hidden when stage1_data arrives   | State transition logic                             |

**Risk Coverage:** Mitigates RISK-015 (poor loading UX)

---

## Risk Coverage Matrix

| Risk ID     | Risk Description                          | Mitigating Tests                  | Priority |
| ----------- | ----------------------------------------- | --------------------------------- | -------- |
| RISK-001    | Polling does not start on mount           | 3.3-INT-001                       | P0       |
| RISK-002    | Incorrect polling interval                | 3.3-INT-002                       | P0       |
| RISK-003    | Infinite polling (status never stops)     | 3.3-INT-005, 3.3-INT-006          | P0       |
| RISK-004    | No initial data fetch                     | 3.3-INT-004                       | P0       |
| RISK-005    | Incorrect stage display                   | 3.3-UNIT-001, 3.3-UNIT-002        | P1       |
| RISK-006    | No visual feedback on active stage        | 3.3-UNIT-004, 3.3-INT-008         | P1       |
| RISK-007    | Incorrect status calculation logic        | 3.3-UNIT-005, 3.3-UNIT-006, 3.3-UNIT-007 | P0  |
| RISK-008    | Track cards display prematurely           | 3.3-INT-009, 3.3-INT-010          | P0       |
| RISK-009    | Missing track card fields                 | 3.3-INT-011                       | P1       |
| RISK-010    | Stale detail panel content                | 3.3-INT-012, 3.3-INT-013          | P1       |
| RISK-011    | User cannot exit pipeline page            | 3.3-INT-014, 3.3-INT-015, 3.3-E2E-007 | P0   |
| RISK-012    | **Memory leaks from polling**             | 3.3-INT-016, 3.3-INT-017          | **P0**   |
| RISK-013    | Poor error UX (no user feedback)          | 3.3-INT-018, 3.3-INT-019          | P1       |
| RISK-014    | Network failure causes infinite retry     | 3.3-INT-020, 3.3-INT-021          | P0       |
| RISK-015    | Poor loading UX (no skeleton)             | 3.3-INT-022, 3.3-INT-023          | P2       |

---

## Recommended Execution Order

### Phase 1: P0 Critical Tests (Fail Fast)
1. **3.3-UNIT-005, 3.3-UNIT-006, 3.3-UNIT-007** - Status calculation logic (foundation)
2. **3.3-INT-001, 3.3-INT-002** - Polling starts and interval (core behavior)
3. **3.3-INT-004, 3.3-INT-005, 3.3-INT-006** - Initial fetch and stop conditions
4. **3.3-INT-016, 3.3-INT-017** - Memory leak prevention (**CRITICAL**)
5. **3.3-INT-009, 3.3-INT-010** - Track card conditional rendering
6. **3.3-INT-014, 3.3-INT-015** - Completion button navigation
7. **3.3-INT-020** - Network retry logic
8. **3.3-E2E-007** - End-to-end critical path

### Phase 2: P1 Core Functionality Tests
9. **3.3-UNIT-001, 3.3-UNIT-002, 3.3-UNIT-003, 3.3-UNIT-004** - StageBox component logic
10. **3.3-UNIT-008** - TrackCard component logic
11. **3.3-INT-003, 3.3-INT-007, 3.3-INT-008** - Component composition
12. **3.3-INT-011, 3.3-INT-012, 3.3-INT-013** - Data display integration
13. **3.3-INT-018, 3.3-INT-019, 3.3-INT-021** - Error handling
14. **3.3-E2E-001, 3.3-E2E-002, 3.3-E2E-004, 3.3-E2E-005** - User journeys

### Phase 3: P2 Polish Tests (If Time Permits)
15. **3.3-INT-007** - Vertical layout
16. **3.3-INT-022, 3.3-INT-023** - Skeleton loaders
17. **3.3-E2E-003, 3.3-E2E-006** - Visual regression tests

---

## Test Implementation Guidance

### Unit Tests (Jest + React Testing Library)

**File:** `__tests__/components/pipeline/StageBox.test.tsx`

```typescript
import { render, screen } from '@testing-library/react'
import { StageBox } from '@/components/pipeline/StageBox'

describe('StageBox', () => {
  it('[3.3-UNIT-001] renders stage number correctly', () => {
    render(<StageBox stageNumber={2} stageName="Signals" status="running" />)
    expect(screen.getByText(/Stage 2/i)).toBeInTheDocument()
  })

  it('[3.3-UNIT-002] renders stage name correctly', () => {
    render(<StageBox stageNumber={1} stageName="Tracks" status="pending" />)
    expect(screen.getByText(/Tracks/i)).toBeInTheDocument()
  })

  it('[3.3-UNIT-003] displays correct icon for status', () => {
    const { rerender } = render(<StageBox stageNumber={1} stageName="Tracks" status="completed" />)
    expect(screen.getByText('✓')).toBeInTheDocument()

    rerender(<StageBox stageNumber={1} stageName="Tracks" status="running" />)
    expect(screen.getByText('⏳')).toBeInTheDocument()

    rerender(<StageBox stageNumber={1} stageName="Tracks" status="pending" />)
    expect(screen.getByText('⌛')).toBeInTheDocument()
  })

  it('[3.3-UNIT-004] applies running styles with animation', () => {
    const { container } = render(<StageBox stageNumber={1} stageName="Tracks" status="running" />)
    const stageBox = container.querySelector('.animate-pulse')
    expect(stageBox).toBeInTheDocument()
    expect(stageBox).toHaveClass('border-2', 'border-blue-700')
  })
})
```

**File:** `__tests__/utils/stageStatus.test.ts`

```typescript
import { calculateStageStatus } from '@/lib/stageStatus'

describe('Stage Status Calculation', () => {
  it('[3.3-UNIT-005] marks stages < current as completed', () => {
    expect(calculateStageStatus(1, 3)).toBe('completed')
    expect(calculateStageStatus(2, 3)).toBe('completed')
  })

  it('[3.3-UNIT-006] marks stages > current as pending', () => {
    expect(calculateStageStatus(4, 3)).toBe('pending')
    expect(calculateStageStatus(5, 3)).toBe('pending')
  })

  it('[3.3-UNIT-007] marks stage = current as running', () => {
    expect(calculateStageStatus(3, 3)).toBe('running')
  })
})
```

---

### Integration Tests (Jest + React Testing Library + Mock API)

**File:** `__tests__/pages/pipeline/PipelinePage.test.tsx`

```typescript
import { render, screen, waitFor, act } from '@testing-library/react'
import { useRouter, useParams } from 'next/navigation'
import PipelinePage from '@/app/pipeline/[runId]/page'

jest.mock('next/navigation', () => ({
  useRouter: jest.fn(),
  useParams: jest.fn(),
}))

describe('PipelinePage Polling', () => {
  beforeEach(() => {
    jest.useFakeTimers()
    ;(useParams as jest.Mock).mockReturnValue({ runId: 'test-001' })
    ;(useRouter as jest.Mock).mockReturnValue({ push: jest.fn() })
  })

  afterEach(() => {
    jest.clearAllTimers()
    jest.useRealTimers()
  })

  it('[3.3-INT-001] polling starts immediately on mount', async () => {
    global.fetch = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ status: 'running', current_stage: 1 }),
      })
    ) as jest.Mock

    render(<PipelinePage />)

    await waitFor(() => {
      expect(fetch).toHaveBeenCalledWith('/api/status/test-001')
    })
  })

  it('[3.3-INT-002] polling interval is exactly 5000ms', async () => {
    global.fetch = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ status: 'running', current_stage: 1 }),
      })
    ) as jest.Mock

    render(<PipelinePage />)

    await waitFor(() => expect(fetch).toHaveBeenCalledTimes(1))

    act(() => { jest.advanceTimersByTime(5000) })

    await waitFor(() => expect(fetch).toHaveBeenCalledTimes(2))
  })

  it('[3.3-INT-004] initial fetch occurs before first interval', async () => {
    const fetchSpy = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ status: 'running', current_stage: 0 }),
      })
    )
    global.fetch = fetchSpy as jest.Mock

    render(<PipelinePage />)

    // Should be called immediately (before any timeout)
    await waitFor(() => expect(fetchSpy).toHaveBeenCalledTimes(1))
    expect(jest.getTimerCount()).toBeGreaterThan(0) // Timeout scheduled
  })

  it('[3.3-INT-005] polling stops when status=complete', async () => {
    global.fetch = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ status: 'complete', current_stage: 5 }),
      })
    ) as jest.Mock

    render(<PipelinePage />)

    await waitFor(() => expect(fetch).toHaveBeenCalledTimes(1))

    act(() => { jest.advanceTimersByTime(10000) })

    expect(fetch).toHaveBeenCalledTimes(1) // No additional calls
  })

  it('[3.3-INT-006] polling stops when status=error', async () => {
    global.fetch = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ status: 'error', current_stage: 2 }),
      })
    ) as jest.Mock

    render(<PipelinePage />)

    await waitFor(() => expect(fetch).toHaveBeenCalledTimes(1))

    act(() => { jest.advanceTimersByTime(10000) })

    expect(fetch).toHaveBeenCalledTimes(1)
  })

  it('[3.3-INT-016, 3.3-INT-017] useEffect cleanup clears timeout', async () => {
    global.fetch = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ status: 'running', current_stage: 1 }),
      })
    ) as jest.Mock

    const { unmount } = render(<PipelinePage />)

    await waitFor(() => expect(fetch).toHaveBeenCalledTimes(1))

    expect(jest.getTimerCount()).toBeGreaterThan(0)

    unmount()

    expect(jest.getTimerCount()).toBe(0) // All timeouts cleared
  })

  it('[3.3-INT-020] network error retries once before failing', async () => {
    let callCount = 0
    global.fetch = jest.fn(() => {
      callCount++
      if (callCount === 1) {
        return Promise.reject(new Error('Network error'))
      }
      return Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ status: 'running', current_stage: 1 }),
      })
    }) as jest.Mock

    render(<PipelinePage />)

    await waitFor(() => expect(fetch).toHaveBeenCalledTimes(2))
  })
})

describe('PipelinePage Track Display', () => {
  it('[3.3-INT-009] track cards display when stage1_data present', async () => {
    global.fetch = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({
          status: 'running',
          current_stage: 1,
          stage1_data: {
            track_1: { title: 'Track A', summary: 'Summary A' },
            track_2: { title: 'Track B', summary: 'Summary B' },
          },
        }),
      })
    ) as jest.Mock

    render(<PipelinePage />)

    await waitFor(() => {
      expect(screen.getByText(/Track A/i)).toBeInTheDocument()
      expect(screen.getByText(/Track B/i)).toBeInTheDocument()
    })
  })

  it('[3.3-INT-010] track cards hidden when stage1_data null', async () => {
    global.fetch = jest.fn(() =>
      Promise.resolve({
        ok: true,
        json: () => Promise.resolve({
          status: 'running',
          current_stage: 1,
          stage1_data: null,
        }),
      })
    ) as jest.Mock

    render(<PipelinePage />)

    await waitFor(() => {
      expect(screen.queryByText(/Track 1:/i)).not.toBeInTheDocument()
    })
  })
})
```

---

### E2E Tests (Playwright)

**File:** `e2e/pipeline-monitoring.spec.ts`

```typescript
import { test, expect } from '@playwright/test'

test.describe('Pipeline Monitoring E2E', () => {
  test('[3.3-E2E-007] complete pipeline → click button → results page', async ({ page }) => {
    // Mock API to simulate completion
    await page.route('**/api/status/test-run-001', async (route) => {
      await route.fulfill({
        status: 200,
        body: JSON.stringify({
          status: 'complete',
          current_stage: 5,
          stage1_data: { /* mock data */ },
        }),
      })
    })

    await page.goto('/pipeline/test-run-001')

    await expect(page.locator('text=View Opportunities →')).toBeVisible()

    await page.click('text=View Opportunities →')

    await expect(page).toHaveURL('/results/test-run-001')
  })

  test('[3.3-E2E-004] stage progression shows correct icons', async ({ page }) => {
    await page.route('**/api/status/test-run-001', async (route) => {
      await route.fulfill({
        status: 200,
        body: JSON.stringify({
          status: 'running',
          current_stage: 3,
          stage1_data: null,
        }),
      })
    })

    await page.goto('/pipeline/test-run-001')

    // Completed stages (1, 2) have checkmarks
    await expect(page.locator('[data-stage="1"]').locator('text=✓')).toBeVisible()
    await expect(page.locator('[data-stage="2"]').locator('text=✓')).toBeVisible()

    // Running stage (3) has hourglass
    await expect(page.locator('[data-stage="3"]').locator('text=⏳')).toBeVisible()

    // Pending stages (4, 5) are grayed
    await expect(page.locator('[data-stage="4"]').locator('text=⌛')).toBeVisible()
    await expect(page.locator('[data-stage="5"]').locator('text=⌛')).toBeVisible()
  })
})
```

---

## Coverage Gaps

None identified. All 12 acceptance criteria have comprehensive test coverage.

---

## Quality Checklist

- [x] Every AC has test coverage
- [x] Test levels are appropriate (not over-testing)
- [x] No duplicate coverage across levels
- [x] Priorities align with business risk
- [x] Test IDs follow naming convention
- [x] Scenarios are atomic and independent

---

## Key Recommendations

### 1. **Memory Leak Testing is CRITICAL (P0)**
Tests 3.3-INT-016 and 3.3-INT-017 MUST pass before deployment. Use React DevTools Profiler to verify:
- No setTimeout remains after unmount
- No memory growth during repeated mount/unmount cycles

### 2. **Network Retry Logic (P0)**
Test 3.3-INT-020 validates resilience to transient failures. Consider:
- Retry once after 5 seconds
- Then display error UI
- Do NOT retry infinitely

### 3. **E2E Test Stability**
E2E tests 3.3-E2E-001 through 3.3-E2E-007 may be flaky due to timing. Recommend:
- Use `waitFor` with appropriate timeouts
- Mock API responses for deterministic behavior
- Visual regression tests (E2E-003, E2E-006) are P2 - defer if time-constrained

### 4. **Test Execution Strategy**
- **CI/CD:** Run P0 unit + integration tests on every commit
- **Pre-merge:** Run all P0 and P1 tests
- **Pre-release:** Run full suite including P2 visual regression

---

## Gate YAML Block

```yaml
test_design:
  scenarios_total: 24
  by_level:
    unit: 8
    integration: 15
    e2e: 7
  by_priority:
    p0: 10
    p1: 10
    p2: 4
  coverage_gaps: []
  critical_risks_addressed:
    - RISK-012: Memory leaks (3.3-INT-016, 3.3-INT-017)
    - RISK-011: User navigation blocked (3.3-INT-014, 3.3-INT-015, 3.3-E2E-007)
    - RISK-003: Infinite polling (3.3-INT-005, 3.3-INT-006)
  recommended_execution_order:
    - "Phase 1: P0 Critical (8 scenarios)"
    - "Phase 2: P1 Core (10 scenarios)"
    - "Phase 3: P2 Polish (4 scenarios)"
```

---

## Summary for Development Team

This test design provides **comprehensive yet efficient** coverage for Story 3.3. The 24 scenarios are strategically distributed across test levels to avoid redundancy while ensuring critical paths are validated.

**Key Takeaways:**
- **Memory leak prevention (P0):** Non-negotiable - must verify cleanup
- **Polling behavior (P0):** Core UX feature - must work reliably
- **User journey exit path (P0):** Users must be able to navigate to results
- **Visual polish (P2):** Nice-to-have - defer if time-constrained

Estimated implementation time: **4-6 hours** for P0+P1 tests, **+2 hours** for P2 tests.
