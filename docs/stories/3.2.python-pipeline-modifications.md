# Story 3.2: Python Pipeline Modifications for Web Interface

---

## Status

**Approved**

---

## Story

**As a** Python pipeline developer,
**I want** to add CLI arguments and JSON output for web-triggered execution,
**so that** the pipeline can be invoked from API routes while maintaining backward compatibility with existing CLI workflows.

---

## Acceptance Criteria

1. Add `--input-file` CLI argument to accept direct PDF file path (e.g., `/tmp/run-123456.pdf`)
2. Add `--run-id` CLI argument to accept unique run identifier (e.g., `run-123456`)
3. Add `--selected-track` CLI argument to accept track selection (1 or 2) from Story 2.2 UI
4. Create `run_from_uploaded_file(input_file_path, brand_id, run_id, selected_track)` function that executes all 5 stages sequentially
5. Function creates output directory `data/test-outputs/{run_id}/` and sets up logging to `{run_id}/logs/pipeline.log`
6. Function reads PDF using PyPDF/pypdf library and extracts text content
7. Function logs stage start/completion messages (e.g., "Starting Stage 1", "Stage 1 execution completed")
8. Modify `Stage1Chain.save_output()` to generate both markdown and JSON files
9. JSON file structure: `{ selected_track: 1, track_1: { title, summary, icon_url }, track_2: { title, summary, icon_url }, completed_at }` (selected_track is single integer: 1 or 2, passed from Story 2.2)
10. Add `_parse_inspirations(output)` method to extract track data from markdown with fallback handling
11. Update `STAGE1_TEMPLATE` prompt to explicitly request exactly 2 tracks in parseable format
12. Process only the selected track through Stages 2-5 (ignore non-selected track)
13. Existing CLI modes (`--batch`, `--input`, `--brand`) continue working unchanged
14. Pipeline output quality and format remain consistent between CLI and web execution

---

## Tasks / Subtasks

- [ ] **Task 1: Add new CLI arguments** (AC: 1, 2)
  - [ ] Open `scripts/run_pipeline.py`
  - [ ] Add `--input-file` argument: `parser.add_argument('--input-file', type=str, help='Direct PDF file path')`
  - [ ] Add `--run-id` argument: `parser.add_argument('--run-id', type=str, help='Unique run identifier')`
  - [ ] Update help text to document new arguments
  - [ ] Test argument parsing: `python scripts/run_pipeline.py --help`

- [ ] **Task 2: Create `run_from_uploaded_file()` function** (AC: 3, 4, 5, 6)
  - [ ] Add `from pypdf import PdfReader` import
  - [ ] Create function signature: `def run_from_uploaded_file(input_file_path: str, brand_id: str, run_id: str) -> None:`
  - [ ] Create output directory: `output_dir = Path(f"data/test-outputs/{run_id}")`
  - [ ] Call `setup_pipeline_logging(output_dir)` (existing utility)
  - [ ] Read PDF: `reader = PdfReader(input_file_path)`, extract text from all pages
  - [ ] Load brand profile: `brand_profile = load_brand_profile(brand_id)` (existing function)
  - [ ] Load research data: `research_data = load_research_data(brand_id)` (existing function)
  - [ ] Add logging statements: `logger.info("Starting Stage 1: Input Processing")`
  - [ ] Execute Stage 1: `stage1_chain = Stage1Chain()`, `stage1_result = stage1_chain.run(input_text)`
  - [ ] Save Stage 1 output: `stage1_chain.save_output(stage1_output, output_dir)`
  - [ ] Add logging: `logger.info("Stage 1 execution completed")`
  - [ ] Repeat for Stages 2-5 using existing code pattern

- [ ] **Task 3: Update `main()` function** (AC: 3, 11)
  - [ ] Add conditional for web execution mode:
    ```python
    if args.input_file and args.brand and args.run_id:
        run_from_uploaded_file(args.input_file, args.brand, args.run_id)
        sys.exit(0)
    ```
  - [ ] Place before existing `--batch` and `--input` conditionals
  - [ ] Verify existing modes still execute (no breaking changes)

- [ ] **Task 4: Modify Stage 1 JSON output** (AC: 7, 8, 9)
  - [ ] Open `pipeline/stages/stage1_input_processing.py`
  - [ ] Add imports: `import json`, `from datetime import datetime`
  - [ ] Modify `save_output()` method:
    - [ ] Keep existing markdown save: `markdown_path.write_text(output, encoding='utf-8')`
    - [ ] Call new parsing method: `tracks = self._parse_inspirations(output)`
    - [ ] Create JSON structure with `selected_tracks`, `track_1`, `track_2`, `completed_at`
    - [ ] Write JSON file: `json_path = stage1_dir / "inspirations.json"`
    - [ ] Use `json.dumps(json_data, indent=2)`
  - [ ] Create `_parse_inspirations(self, output: str) -> list` method:
    - [ ] Use regex to extract Track 1: `r'## Track 1: (.+?)\n\n(.+?)(?=\n\n##|\Z)'`
    - [ ] Use regex to extract Track 2: `r'## Track 2: (.+?)\n\n(.+?)(?=\n\n##|\Z)'`
    - [ ] Return list of dicts: `[{ "title": ..., "summary": ..., "icon_url": "" }, ...]`
    - [ ] Add fallback if parsing fails (return generic track data)

- [ ] **Task 5: Update Stage 1 prompt** (AC: 10)
  - [ ] Open `pipeline/stages/stage1_input_processing.py`
  - [ ] Find `STAGE1_TEMPLATE` constant
  - [ ] Update prompt to explicitly request exactly 2 tracks
  - [ ] Add format instructions: "## Track 1: [Title]\n\n[Content]"
  - [ ] Add note: "The system will auto-select these top 2 tracks. Do not include additional tracks."

- [ ] **Task 6: Testing and verification** (AC: 11, 12)
  - [ ] Test new web execution: `python scripts/run_pipeline.py --input-file data/test-inputs/savannah-bananas.pdf --brand lactalis-canada --run-id test-web-001`
  - [ ] Verify JSON created: `cat data/test-outputs/test-web-001/stage1/inspirations.json | jq .`
  - [ ] Verify markdown unchanged: `cat data/test-outputs/test-web-001/stage1/inspiration-analysis.md`
  - [ ] Test existing batch mode: `python scripts/run_pipeline.py --batch`
  - [ ] Verify all 4 test runs complete successfully
  - [ ] Compare opportunity card outputs (CLI vs web) for quality consistency

---

## Dev Notes

### Architecture Context

**Python Pipeline Structure:**
- Entry point: `scripts/run_pipeline.py`
- Stage implementations: `pipeline/stages/stage{1-5}_*.py`
- Base class: `pipeline/stages/stage1_input_processing.py` (Stage1Chain inherits from BaseStage)
- Utilities: `pipeline/utils.py` (logging, brand loading)

**Existing Execution Modes:**
1. `--batch`: Run all test inputs for all brands
2. `--input` + `--brand`: Run single PDF with specific brand
3. **NEW:** `--input-file` + `--brand` + `--run-id`: Web-triggered execution

**Output Directory Structure:**
```
data/test-outputs/{run_id}/
├── logs/
│   └── pipeline.log
├── stage1/
│   ├── inspiration-analysis.md  (existing)
│   └── inspirations.json        (NEW)
├── stage2/
│   └── trend-signals.md
├── stage3/
│   └── universal-lessons.md
├── stage4/
│   └── brand-contextualization.md
└── stage5/
    ├── opportunity-1.md
    ├── opportunity-2.md
    ├── opportunity-3.md
    ├── opportunity-4.md
    └── opportunity-5.md
```

### Implementation Patterns

**PDF Reading:**
```python
from pypdf import PdfReader

reader = PdfReader(input_file_path)
input_text = "".join(page.extract_text() for page in reader.pages)
```

**JSON Output (Stage 1):**
```python
import json
from datetime import datetime

def save_output(self, output: str, output_dir: Path) -> Path:
    stage1_dir = output_dir / "stage1"
    stage1_dir.mkdir(parents=True, exist_ok=True)

    # Save markdown (EXISTING)
    markdown_path = stage1_dir / "inspiration-analysis.md"
    markdown_path.write_text(output, encoding='utf-8')

    # Parse tracks (NEW)
    tracks = self._parse_inspirations(output)

    # Save JSON (NEW)
    json_path = stage1_dir / "inspirations.json"
    json_data = {
        "selected_tracks": [1, 2],
        "track_1": tracks[0],
        "track_2": tracks[1],
        "completed_at": datetime.now().isoformat()
    }
    json_path.write_text(json.dumps(json_data, indent=2), encoding='utf-8')

    return markdown_path
```

**Track Parsing:**
```python
def _parse_inspirations(self, output: str) -> list:
    import re

    track1_match = re.search(
        r'## Track 1: (.+?)\n\n(.+?)(?=\n\n##|\Z)',
        output,
        re.DOTALL
    )

    track2_match = re.search(
        r'## Track 2: (.+?)\n\n(.+?)(?=\n\n##|\Z)',
        output,
        re.DOTALL
    )

    if not track1_match or not track2_match:
        # Fallback
        return [
            {"title": "Inspiration Track 1", "summary": "Unable to parse - see markdown", "icon_url": ""},
            {"title": "Inspiration Track 2", "summary": "Unable to parse - see markdown", "icon_url": ""}
        ]

    return [
        {
            "title": track1_match.group(1).strip(),
            "summary": track1_match.group(2).strip()[:200],
            "icon_url": ""
        },
        {
            "title": track2_match.group(1).strip(),
            "summary": track2_match.group(2).strip()[:200],
            "icon_url": ""
        }
    ]
```

**Updated Stage 1 Prompt:**
```python
STAGE1_TEMPLATE = """
Analyze this innovation signal document and extract the TWO most compelling inspiration tracks.

IMPORTANT: Only extract the TOP 2 most impactful inspiration tracks. These will be displayed
in a vertical pipeline UI and used for all subsequent analysis stages.

Format your response EXACTLY as follows:

## Track 1: [Give it a descriptive title]

[Write 2-3 sentences summarizing the first main inspiration or pattern you identify]

## Track 2: [Give it a descriptive title]

[Write 2-3 sentences summarizing the second main inspiration or pattern you identify]

NOTE: The system will auto-select these top 2 tracks for the pipeline. Do not include
additional tracks beyond these two.

Input Document:
{input_text}
"""
```

### Source Tree (Relevant Files)

**Files to Modify:**
- `scripts/run_pipeline.py` - Add CLI args, add `run_from_uploaded_file()` function
- `pipeline/stages/stage1_input_processing.py` - Add JSON output, `_parse_inspirations()`, update prompt

**Files to Read (Existing):**
- `pipeline/utils.py` - Logging utilities, brand profile loading
- `data/brand-profiles/{brand_id}.yaml` - Brand profile data
- `data/test-inputs/savannah-bananas.pdf` - Test PDF

**Dependencies:**
```bash
pip install pypdf  # or PyPDF2 if preferred
```

### Critical Constraints

**Backward Compatibility (CRITICAL):**
- Existing `--batch` mode MUST work unchanged
- Existing test outputs MUST remain valid
- No changes to Stages 2-5 execution logic
- Markdown output format MUST stay consistent

**PDF Library:**
- Use `pypdf` (lightweight, modern) or `PyPDF2` (if already in requirements)
- Must handle various PDF formats gracefully

**JSON Parsing:**
- Must handle LLM output variations (extra whitespace, formatting)
- Fallback required if regex fails
- Log parsing failures for debugging

### Risk Mitigation

**Primary Risk:** Stage 1 JSON parsing fails with unpredictable LLM output
- **Mitigation:** Flexible regex with `re.DOTALL`, fallback response
- **Fallback:** Display full markdown in single card UI

**Secondary Risk:** PDF reading fails with certain files
- **Mitigation:** Try-except with clear error message
- **Fallback:** Revert to text file input only

---

## Testing

### Test File Locations
- Unit tests: `tests/pipeline/test_stage1_json_output.py`
- Integration tests: `tests/pipeline/test_web_execution.py`

### Testing Standards
- Use pytest for Python unit tests
- Test JSON structure with `json.loads()` validation
- Regression test existing `--batch` mode
- Compare CLI vs web output for consistency

### Testing Framework
```python
# Example test
def test_parse_inspirations():
    stage1 = Stage1Chain()
    sample_output = "## Track 1: Title\n\nContent here\n\n## Track 2: Title\n\nMore content"
    tracks = stage1._parse_inspirations(sample_output)
    assert len(tracks) == 2
    assert tracks[0]["title"] == "Title"
```

### Specific Testing Requirements
1. Test `_parse_inspirations()` with multiple LLM output formats
2. Test fallback handling when regex fails
3. Test JSON file creation (verify structure with `jq`)
4. Test existing batch mode after all changes
5. Compare opportunity card outputs (quality regression check)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | 1.0 | Initial story creation | John (PM Agent) |

---

## Dev Agent Record

### Agent Model Used
*To be populated by dev agent*

### Debug Log References
*To be populated by dev agent*

### Completion Notes List
*To be populated by dev agent*

### File List
*To be populated by dev agent*

---

## QA Results

*To be populated by QA agent after story completion*
