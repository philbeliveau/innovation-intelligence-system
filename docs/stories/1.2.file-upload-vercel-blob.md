# Story 1.2: File Upload to Vercel Blob

**Epic:** Epic 1 - Core Upload & File Management
**Priority:** P0
**Estimated Time:** 1 hour

---

## Status

**Draft**

---

## Story

**As a** Innovation Manager,
**I want** to upload market signal documents (PDFs, text files, markdown) to cloud storage,
**so that** the pipeline can process my files and generate brand-specific innovation opportunities.

---

## Acceptance Criteria

1. API route exists at `POST /api/upload`
2. Endpoint accepts multipart/form-data with single file field
3. Returns JSON response with structure: `{upload_id, blob_url, file_name, file_size, uploaded_at}`
4. Accepts only file types: `application/pdf`, `text/plain`, `text/markdown`
5. File extensions must match MIME type (`.pdf`, `.txt`, `.md`)
6. Rejects invalid file types with 400 status and error: `{"error": "Invalid file type"}`
7. Maximum file size is 25MB (Vercel Blob limit)
8. Rejects oversized files with 400 status and error: `{"error": "File too large (max 25MB)"}`
9. File size check happens before upload to Blob
10. Files stored with path pattern: `uploads/{timestamp}-{original-filename}`
11. Blob access level is `public` (allows direct URL access)
12. Blob URL is publicly accessible without authentication
13. Upload completes in < 5 seconds for 10MB file
14. Python pipeline file reading remains unchanged (expects local file paths)
15. No modifications to `scripts/run_pipeline.py` in this story
16. Upload ID format: `upload-{unix-timestamp-milliseconds}`
17. Upload ID is unique per upload (timestamp ensures uniqueness)
18. Upload ID used as key for tracking throughout system
19. API reads `BLOB_READ_WRITE_TOKEN` from environment variables
20. Handles Vercel Blob SDK errors gracefully
21. Returns 500 status if Blob service unavailable
22. Missing file in request returns: `{"error": "No file provided"}` (400)
23. Blob upload failure returns: `{"error": "Upload failed"}` (500)
24. Network timeout returns: `{"error": "Upload timeout"}` (500)
25. All errors logged server-side with stack traces
26. Implements retry logic: 3 attempts with exponential backoff (1s, 2s, 4s)
27. Temporary failures trigger retry before returning error
28. API response time < 2 seconds for files under 5MB
29. No memory leaks (files streamed, not fully loaded to memory)
30. Concurrent uploads supported (no file locking issues)

---

## Tasks / Subtasks

- [ ] Task 1: Install dependencies (AC: 19, 20)
  - [ ] Install Vercel Blob SDK: `npm install @vercel/blob`
  - [ ] Verify `@vercel/blob` version ^0.15.0 in package.json

- [ ] Task 2: Configure environment variables (AC: 19)
  - [ ] Add `BLOB_READ_WRITE_TOKEN` to `.env.local`
  - [ ] Document token setup in README or setup guide
  - [ ] Verify token is accessible in API route via `process.env.BLOB_READ_WRITE_TOKEN`

- [ ] Task 3: Create API route structure (AC: 1, 2)
  - [ ] Create file: `app/api/upload/route.ts`
  - [ ] Implement POST handler function
  - [ ] Parse multipart/form-data using `await request.formData()`
  - [ ] Extract file from form data: `formData.get('file') as File`

- [ ] Task 4: Implement file validation (AC: 4, 5, 6, 7, 8, 9, 22)
  - [ ] Check if file exists, return 400 if missing
  - [ ] Create allowed types array: `['application/pdf', 'text/plain', 'text/markdown']`
  - [ ] Validate file.type against allowed types
  - [ ] Return 400 with "Invalid file type" error if rejected
  - [ ] Check file.size against 25MB limit: `25 * 1024 * 1024`
  - [ ] Return 400 with "File too large (max 25MB)" error if oversized

- [ ] Task 5: Implement Blob upload with retry (AC: 10, 11, 12, 19, 20, 21, 23, 26, 27)
  - [ ] Import `put` from '@vercel/blob'
  - [ ] Create upload path: `uploads/${Date.now()}-${file.name}`
  - [ ] Implement retry loop: 3 attempts maximum
  - [ ] Call `await put(path, file, {access: 'public'})`
  - [ ] On failure, wait with exponential backoff: `Math.pow(2, attempts) * 1000`ms
  - [ ] After 3 failed attempts, log error and return 500
  - [ ] On success, store blob object with `.url` property

- [ ] Task 6: Generate upload ID and response (AC: 3, 16, 17, 18)
  - [ ] Generate upload_id: `upload-${Date.now()}`
  - [ ] Create response object with: upload_id, blob_url, file_name, file_size, uploaded_at
  - [ ] Return JSON with 200 status: `NextResponse.json({...})`

- [ ] Task 7: Implement error handling (AC: 21, 22, 23, 24, 25)
  - [ ] Wrap all logic in try-catch block
  - [ ] Log all errors server-side: `console.error('Upload error:', error)`
  - [ ] Return appropriate status codes: 400 for validation, 500 for server errors
  - [ ] Return descriptive error messages in JSON format
  - [ ] Handle network timeouts (Vercel 60s function timeout)

- [ ] Task 8: Performance optimization (AC: 13, 28, 29, 30)
  - [ ] Verify file streaming (Blob SDK handles this automatically)
  - [ ] Test with 10MB file, ensure < 5 second completion
  - [ ] Test with 5MB file, ensure < 2 second response
  - [ ] Test concurrent uploads (multiple files at once)
  - [ ] Monitor memory usage during uploads

- [ ] Task 9: API testing (AC: all)
  - [ ] Test valid PDF upload (< 5 seconds for 10MB)
  - [ ] Test valid TXT upload
  - [ ] Test valid MD upload
  - [ ] Test invalid file type (.exe) - expect 400 error
  - [ ] Test oversized file (30MB) - expect 400 error
  - [ ] Test missing file - expect 400 error
  - [ ] Test with invalid Blob token - expect 500 error
  - [ ] Verify blob URL is publicly accessible (curl test)
  - [ ] Test retry logic by simulating network issues

- [ ] Task 10: CLI regression testing (AC: 14, 15)
  - [ ] Verify Python pipeline still works with local files
  - [ ] Run: `python scripts/run_pipeline.py --brand lactalis-canada --input data/test-inputs/savannah-bananas.pdf`
  - [ ] Confirm no breaking changes to pipeline

---

## Dev Notes

### Existing System Integration
- **Integration Point:** Python pipeline expects local file paths (`--input-file /path/to/file.pdf`)
- **No Changes:** Python pipeline code (`scripts/run_pipeline.py`) remains unchanged in this story
- **Future Integration:** Epic 3 will download from Blob URL to `/tmp/` before pipeline execution
- **Technology Stack:** Next.js 15 API Routes, Vercel Blob SDK, Node.js 20.x

### API Route Location
- **File:** `app/api/upload/route.ts`
- **HTTP Method:** POST
- **Content-Type:** multipart/form-data
- **Response Format:** JSON

### Vercel Blob Configuration
- **Storage Path Pattern:** `uploads/{timestamp}-{filename}`
- **Access Level:** `public` (no authentication required for URL access)
- **Token:** `BLOB_READ_WRITE_TOKEN` environment variable
- **Free Tier:** 1GB storage (sufficient for hackathon)
- **File Size Limit:** 25MB (enforced by API validation)

### Upload ID Format
- **Format:** `upload-{unix-timestamp-milliseconds}`
- **Example:** `upload-1729349025123`
- **Purpose:** Unique identifier for tracking upload throughout system
- **Usage:** Key for sessionStorage (Story 1.3) and pipeline execution (Epic 3)

### Retry Logic
- **Attempts:** 3 maximum
- **Backoff:** Exponential (1s, 2s, 4s)
- **Algorithm:** `Math.pow(2, attempts) * 1000` milliseconds
- **Failure:** After 3 attempts, return 500 error

### Response Schema
```typescript
{
  upload_id: string,           // "upload-1729349025123"
  blob_url: string,            // "https://blob.vercel-storage.com/uploads/..."
  file_name: string,           // "savannah-bananas.pdf"
  file_size: number,           // 1234567 (bytes)
  uploaded_at: string          // "2025-10-19T14:23:45.123Z" (ISO 8601)
}
```

### Error Handling
| Scenario | Status | Error Message |
|----------|--------|---------------|
| Missing file | 400 | `{"error": "No file provided"}` |
| Invalid file type | 400 | `{"error": "Invalid file type"}` |
| File too large | 400 | `{"error": "File too large (max 25MB)"}` |
| Blob upload failed | 500 | `{"error": "Upload failed"}` |
| Network timeout | 500 | `{"error": "Upload timeout"}` |

### Dependencies
```json
{
  "dependencies": {
    "@vercel/blob": "^0.15.0"
  }
}
```

### Environment Variables
```bash
# .env.local
BLOB_READ_WRITE_TOKEN=vercel_blob_rw_...
```

**How to get token:**
1. Deploy to Vercel (or run `vercel env pull`)
2. Token auto-generated on first Blob operation
3. Copy from Vercel dashboard > Storage > Blob > Settings

### Code Structure
```typescript
// app/api/upload/route.ts
import { put } from '@vercel/blob'
import { NextResponse } from 'next/server'

export async function POST(request: Request) {
  // 1. Extract file from form data
  // 2. Validate file type and size
  // 3. Upload to Blob with retry logic
  // 4. Generate upload ID
  // 5. Return response with metadata
}
```

### Testing

#### Test File Location
- Use existing test file: `data/test-inputs/savannah-bananas.pdf`
- Create additional test files: small.txt, large.md, oversized.pdf (30MB)

#### Testing Standards
- **API Testing:** Use curl or Postman for HTTP requests
- **Performance:** Measure response time with `time` command
- **Error Scenarios:** Test all validation and error cases
- **Concurrent Uploads:** Test multiple simultaneous uploads

#### Testing Frameworks and Patterns
- Manual API testing with curl
- No automated tests for hackathon scope
- Performance testing with time measurement

#### Specific Testing Requirements
1. Test all 3 supported file types (PDF, TXT, MD)
2. Test file size boundaries (1MB, 10MB, 24MB, 30MB)
3. Test invalid file types (.exe, .jpg, .zip)
4. Verify blob URL is publicly accessible (curl GET)
5. Test retry logic (simulate network failure)
6. Verify Python CLI still works unchanged

### Test Commands
```bash
# Test valid PDF upload
curl -X POST http://localhost:3000/api/upload \
  -F "file=@data/test-inputs/savannah-bananas.pdf"

# Test invalid file type
curl -X POST http://localhost:3000/api/upload \
  -F "file=@test.exe"

# Test oversized file
dd if=/dev/zero of=large.pdf bs=1M count=30
curl -X POST http://localhost:3000/api/upload \
  -F "file=@large.pdf"

# Verify blob URL accessibility
BLOB_URL="<url_from_response>"
curl -I $BLOB_URL  # Expect: HTTP 200 OK
```

### Rollback Plan
If Blob storage fails:
1. Modify API to save files to `/tmp/` directory
2. Return local file path instead of Blob URL
3. Pipeline reads from `/tmp/` instead of downloading

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | 1.0 | Initial story creation using BMAD template | John (PM Agent) |

---

## Dev Agent Record

### Agent Model Used

*To be populated by dev agent during implementation*

### Debug Log References

*To be populated by dev agent during implementation*

### Completion Notes List

*To be populated by dev agent during implementation*

### File List

*To be populated by dev agent during implementation*

Expected files:
- `app/api/upload/route.ts`
- `.env.local` (updated with BLOB_READ_WRITE_TOKEN)
- `package.json` (updated with @vercel/blob dependency)

---

## QA Results

*To be populated by QA agent after implementation*
