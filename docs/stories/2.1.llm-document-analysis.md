# Story 2.1: LLM Document Analysis API

---

## Status

**Draft**

---

## Story

**As a** Innovation Manager,
**I want** the system to automatically analyze uploaded documents using LLM to extract key insights, themes, and ideation tracks,
**so that** I can quickly understand the document's content without manual reading before launching the innovation pipeline.

---

## Acceptance Criteria

1. **API Endpoint Creation**
   - Create `POST /api/analyze-document` route handler
   - Accept JSON request body with `blob_url` parameter
   - Return structured JSON response with analysis results
   - Handle errors with appropriate HTTP status codes (400, 500)

2. **PDF Text Extraction**
   - Download PDF from Vercel Blob URL
   - Extract full text content from PDF using `pdf-parse` library
   - Handle multi-page PDFs correctly
   - Limit text extraction to first 4000 characters for LLM processing
   - Handle corrupted or unreadable PDFs gracefully

3. **LLM Integration for Analysis**
   - Use LangChain with OpenRouter API (Claude Sonnet 4.5 via DeepSeek)
   - Send document text to LLM with structured analysis prompt
   - Request extraction of: title, summary, industry, theme, sources, tracks
   - Parse LLM response as JSON
   - Handle LLM API failures with retries (up to 3 attempts)

4. **Document Metadata Extraction**
   - Extract compelling title (10-15 words) capturing main innovation/trend
   - Generate concise summary (2-3 sentences, ~50 words)
   - Identify primary industry (single word: fashion, food, technology, healthcare, sports, etc.)
   - Identify main theme/topic (2-3 words: e.g., "marketing strategies", "sustainability")
   - Extract identifiable sources mentioned (website names, publications)

5. **Ideation Tracks Identification**
   - LLM identifies 2 main ideation tracks from document
   - Each track includes: title, summary (2-3 sentences), optional icon_url
   - Tracks represent distinct innovation patterns or themes
   - Auto-select both tracks for pipeline processing (MVP: no manual selection)

6. **Response Format**
   - Return JSON with structure:
     ```json
     {
       "upload_id": "upload-{timestamp}",
       "analysis": {
         "title": "string",
         "summary": "string",
         "industry": "string",
         "theme": "string",
         "sources": ["string"],
         "tracks": [
           { "title": "string", "summary": "string", "icon_url": "string?" },
           { "title": "string", "summary": "string", "icon_url": "string?" }
         ]
       },
       "blob_url": "string",
       "analyzed_at": "ISO 8601 timestamp"
     }
     ```

7. **Error Handling**
   - Return 400 for invalid/missing blob_url
   - Return 500 for LLM analysis failures
   - Log errors for debugging
   - Provide user-friendly error messages in response

8. **Performance Requirements**
   - Complete analysis in 30-60 seconds
   - Use streaming or async processing where possible
   - Set reasonable timeout (90 seconds max)

9. **Environment Configuration**
   - Read API credentials from environment variables
   - Use `OPENROUTER_API_KEY`, `OPENROUTER_BASE_URL`, `LLM_MODEL`
   - Validate environment variables on startup

10. **Testing & Validation**
    - Manual test with sample PDF (savannah-bananas.pdf)
    - Verify JSON response structure matches specification
    - Test error scenarios (invalid blob URL, LLM timeout)

---

## Tasks / Subtasks

- [ ] **Task 1: Set Up API Route** (AC: 1, 9)
  - [ ] Create `/app/api/analyze-document/route.ts` file
  - [ ] Add `POST` export function with Next.js 15 route handler pattern
  - [ ] Import `NextResponse` from `next/server`
  - [ ] Add request body parsing: `await request.json()`
  - [ ] Extract `blob_url` from request body
  - [ ] Validate `blob_url` is present, return 400 if missing
  - [ ] Add try-catch block for error handling
  - [ ] Return 500 status for unhandled errors

- [ ] **Task 2: Implement PDF Download and Text Extraction** (AC: 2)
  - [ ] Install `pdf-parse` package: `npm install pdf-parse`
  - [ ] Install Node.js types: `npm install -D @types/pdf-parse`
  - [ ] Download PDF from blob_url using `fetch()`
  - [ ] Convert response to ArrayBuffer
  - [ ] Write buffer to temporary file in `/tmp` directory
  - [ ] Use `pdf-parse` to extract text from buffer
  - [ ] Extract `data.text` property containing full document text
  - [ ] Slice text to first 4000 characters for LLM prompt
  - [ ] Handle PDF parsing errors (corrupted files, unsupported formats)

- [ ] **Task 3: Configure LangChain and OpenRouter Integration** (AC: 3, 9)
  - [ ] Install LangChain: `npm install @langchain/openai langchain`
  - [ ] Import `ChatOpenAI` from `@langchain/openai`
  - [ ] Create LLM instance with configuration:
    - `modelName: process.env.LLM_MODEL || 'anthropic/claude-sonnet-4.5'`
    - `openAIApiKey: process.env.OPENROUTER_API_KEY`
    - `configuration.baseURL: process.env.OPENROUTER_BASE_URL`
  - [ ] Add environment variable validation
  - [ ] Set timeout to 90 seconds
  - [ ] Configure retry logic (3 attempts with exponential backoff)

- [ ] **Task 4: Create LLM Analysis Prompt** (AC: 4, 5)
  - [ ] Design structured prompt requesting:
    - Compelling title (10-15 words)
    - Concise summary (2-3 sentences, ~50 words)
    - Primary industry (single word)
    - Main theme (2-3 words)
    - Identifiable sources (array of strings)
    - 2 ideation tracks with title and summary each
  - [ ] Include document text (first 4000 chars) in prompt
  - [ ] Request JSON-only response format
  - [ ] Add example JSON structure to prompt for clarity
  - [ ] Test prompt with sample document to verify output quality

- [ ] **Task 5: Parse and Validate LLM Response** (AC: 6)
  - [ ] Invoke LLM with prompt: `await llm.invoke(analysisPrompt)`
  - [ ] Extract `result.content` from LLM response
  - [ ] Parse JSON from content: `JSON.parse(result.content)`
  - [ ] Validate required fields exist: title, summary, industry, theme, sources, tracks
  - [ ] Validate tracks array has exactly 2 elements
  - [ ] Validate each track has title and summary
  - [ ] Add fallback values if parsing fails
  - [ ] Log parsing errors for debugging

- [ ] **Task 6: Build Response Object** (AC: 6)
  - [ ] Generate unique `upload_id`: `upload-${Date.now()}`
  - [ ] Construct analysis object with parsed LLM data
  - [ ] Add `blob_url` from request
  - [ ] Add `analyzed_at` timestamp: `new Date().toISOString()`
  - [ ] Return JSON response: `NextResponse.json({ upload_id, analysis, blob_url, analyzed_at })`

- [ ] **Task 7: Add Error Handling and Logging** (AC: 7, 8)
  - [ ] Add console.error logging for debugging
  - [ ] Return structured error responses with messages
  - [ ] Handle blob download failures (404, network errors)
  - [ ] Handle PDF parsing errors (corrupted files)
  - [ ] Handle LLM timeout errors
  - [ ] Handle JSON parsing errors from malformed LLM responses
  - [ ] Add request timeout (90 seconds max)
  - [ ] Log all errors with context (blob_url, error type)

- [ ] **Task 8: Environment Setup** (AC: 9)
  - [ ] Add to `.env.local`:
    ```
    OPENROUTER_API_KEY=sk-or-v1-...
    OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
    LLM_MODEL=anthropic/claude-sonnet-4.5
    ```
  - [ ] Document required environment variables in README
  - [ ] Add validation to check variables exist at runtime
  - [ ] Use fallback values where appropriate

- [ ] **Task 9: Manual Testing** (AC: 10)
  - [ ] Test with sample PDF: `data/test-inputs/savannah-bananas.pdf`
  - [ ] Upload file via Story 1.2 endpoint to get blob_url
  - [ ] Call `/api/analyze-document` with blob_url using curl or Postman
  - [ ] Verify response structure matches specification
  - [ ] Verify analysis quality (title makes sense, tracks are distinct)
  - [ ] Test error scenario: invalid blob_url → expect 400 error
  - [ ] Test error scenario: corrupt PDF → expect 500 error with message
  - [ ] Measure response time (should be 30-60 seconds)
  - [ ] Verify analyzed_at timestamp is valid ISO 8601 format

---

## Dev Notes

### Context from Previous Stories

**Story 1.2 (File Upload to Vercel Blob):**
- Upload endpoint: `POST /api/upload`
- Returns: `{ upload_id, blob_url, file_name, file_size, uploaded_at }`
- Blob URLs are public and accessible via HTTPS
- Example: `https://blob.vercel-storage.com/uploads/1729349025123-savannah-bananas.pdf`

**Story 1.3 (Upload Page UI):**
- After upload, stores `blob_url` in sessionStorage with key `upload_${upload_id}`
- Redirects to `/analyze/{uploadId}` after successful upload
- Story 2.2 will consume this API's response

### Relevant Source Tree

```
innovation-web/
├── app/
│   ├── api/
│   │   ├── analyze-document/
│   │   │   └── route.ts          # CREATE THIS - Main analysis endpoint
│   │   └── upload/
│   │       └── route.ts          # EXISTS from Story 1.2
│   ├── analyze/
│   │   └── [uploadId]/
│   │       └── page.tsx          # Will be created in Story 2.2
│   └── upload/
│       └── page.tsx              # EXISTS from Story 1.3
├── lib/
│   └── llm-config.ts             # OPTIONAL - LLM configuration utilities
└── .env.local                    # Environment variables
```

### Architecture References

**PRD Section 4.5.1 (POST /api/analyze-document):**
- Purpose: Use LLM to extract summary and metadata from uploaded document
- Request: `{ blob_url: string }`
- Response: Analysis object with title, summary, industry, theme, sources, tracks
- Error codes: 400 (invalid blob URL), 500 (LLM analysis failed)
- Processing time: 30-60 seconds

**PRD Section 4.2.1 (Intermediary Card Page):**
- Intermediary card (Story 2.2) will consume this API
- Displays analysis results: title, badges (sources, industry, theme), summary
- Shows 2 ideation tracks for user review before pipeline launch

**Tech Stack:**
- Next.js 15 API Routes (App Router)
- LangChain for LLM orchestration
- OpenRouter API with Claude Sonnet 4.5
- pdf-parse for PDF text extraction
- TypeScript for type safety

**LLM Configuration:**
- Model: `anthropic/claude-sonnet-4.5` (via DeepSeek on OpenRouter)
- Estimated cost: ~$0.10-0.20 per analysis
- Context window: 200K tokens (plenty for 4000 char prompt)
- Temperature: Default (0.7) for balanced creativity/accuracy

### Important Implementation Notes

1. **Prompt Engineering:**
   - Be explicit: "Respond ONLY with valid JSON in this exact format"
   - Provide example JSON structure in prompt
   - Request specific constraints (e.g., "10-15 words" for title)
   - Include first 4000 characters only to stay under token limits

2. **JSON Parsing Safety:**
   - LLM may return markdown code blocks: strip ```json and ``` before parsing
   - Use try-catch around JSON.parse with fallback to empty structure
   - Validate all required fields exist after parsing

3. **Track Generation Logic:**
   - LLM should identify 2 DISTINCT ideation tracks
   - Tracks should represent different innovation patterns/angles
   - Avoid overlapping or redundant tracks
   - Each track summary should be actionable and specific

4. **Temporary File Handling:**
   - Vercel allows `/tmp` directory usage
   - Clean up temp files after processing (optional for MVP)
   - File path: `/tmp/${upload_id}.pdf`

5. **Error Message Standards:**
   - User-facing: "Failed to analyze document. Please try again."
   - Logs: Include technical details (error type, stack trace, blob_url)
   - Avoid exposing API keys or internal paths in responses

### Testing

**Manual Testing Workflow:**

1. **Setup:**
   - Ensure `.env.local` has valid `OPENROUTER_API_KEY`
   - Upload test PDF via Story 1.2's `/api/upload` endpoint
   - Copy `blob_url` from upload response

2. **API Test (using curl):**
   ```bash
   curl -X POST http://localhost:3000/api/analyze-document \
     -H "Content-Type: application/json" \
     -d '{"blob_url": "https://blob.vercel-storage.com/uploads/1729349025123-savannah-bananas.pdf"}'
   ```

3. **Expected Response:**
   ```json
   {
     "upload_id": "upload-1729349025123",
     "analysis": {
       "title": "Savannah Bananas: Reinventing Baseball Through Theatrical Fan Experience",
       "summary": "The Savannah Bananas transformed minor league baseball by prioritizing entertainment over competition, selling out stadiums through choreographed performances, fan interaction, and rule modifications that accelerate gameplay.",
       "industry": "sports",
       "theme": "fan experience innovation",
       "sources": ["savannah-bananas.com", "ESPN", "Forbes"],
       "tracks": [
         {
           "title": "Theatrical Sports Experience",
           "summary": "Creating stadium experiences that blend sports with theater, music, and comedy to engage non-traditional sports fans and increase attendance."
         },
         {
           "title": "Rule Innovation for Engagement",
           "summary": "Modifying traditional game rules to increase pace, excitement, and audience participation, making the sport more accessible and entertaining."
         }
       ]
     },
     "blob_url": "https://blob.vercel-storage.com/uploads/1729349025123-savannah-bananas.pdf",
     "analyzed_at": "2025-10-19T14:23:45.123Z"
   }
   ```

4. **Validation Checks:**
   - [ ] Response time: 30-60 seconds
   - [ ] Title is compelling and 10-15 words
   - [ ] Summary is 2-3 sentences, ~50 words
   - [ ] Industry is single word
   - [ ] Theme is 2-3 words
   - [ ] Sources array has at least 1 item
   - [ ] Tracks array has exactly 2 items
   - [ ] Each track has title and summary
   - [ ] Timestamp is valid ISO 8601 format

**Error Scenario Tests:**

1. **Invalid Blob URL:**
   ```bash
   curl -X POST http://localhost:3000/api/analyze-document \
     -H "Content-Type: application/json" \
     -d '{"blob_url": "https://invalid-url.com/file.pdf"}'
   ```
   Expected: 400 status with error message

2. **Missing Blob URL:**
   ```bash
   curl -X POST http://localhost:3000/api/analyze-document \
     -H "Content-Type: application/json" \
     -d '{}'
   ```
   Expected: 400 status with "Missing blob_url" error

**Test File Location:**
- No automated tests required for MVP (manual testing only)
- Future: `app/api/analyze-document/__tests__/route.test.ts`

**Testing Standards:**
- Manual API testing with curl/Postman
- Visual inspection of analysis quality
- Error scenario coverage
- Performance validation (30-60 second response time)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | 1.0 | Initial story creation from brownfield-create-story task | John (PM Agent) |

---

## Dev Agent Record

### Agent Model Used

*To be populated by dev agent*

### Debug Log References

*To be populated by dev agent*

### Completion Notes List

*To be populated by dev agent*

### File List

*To be populated by dev agent*

---

## QA Results

*To be populated by QA agent after implementation review*
