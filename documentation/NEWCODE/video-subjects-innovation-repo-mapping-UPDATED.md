# Mapping Vid√©os Newcode ‚Üí Innovation Intelligence System

**Branche:** `architecture-cleanup-prisma`
**Repo:** https://github.com/philbeliveau/innovation-intelligence-system

---

## üéØ R√©sum√© Ex√©cutif

Le repo **innovation-intelligence-system** (branche `architecture-cleanup-prisma`) est une **application full-stack moderne COMPL√àTE** avec TOUS les composants n√©cessaires pour 18 sujets vid√©o sur 20.

### **Stack Compl√®te Confirm√©e:**

**Frontend (`innovation-web/`):**
- ‚úÖ Next.js 15.5.6 + React 19.1.0 (App Router)
- ‚úÖ TypeScript strict mode
- ‚úÖ Tailwind CSS 4 + shadcn/ui components
- ‚úÖ Clerk Auth (@clerk/nextjs ^6.33.7)
- ‚úÖ Prisma Client (@prisma/client ^6.18.0)
- ‚úÖ LangChain (@langchain/openai ^1.0.0)
- ‚úÖ Vercel Blob (@vercel/blob ^2.0.0)
- ‚úÖ Jest + Testing Library (tests configur√©s)
- ‚úÖ Dark mode (next-themes)

**Backend (`backend/`):**
- ‚úÖ FastAPI 0.115.0 + Uvicorn
- ‚úÖ LangChain 0.1.20 pipeline (preserved from original)
- ‚úÖ OpenAI integration
- ‚úÖ PDF processing (pypdf)
- ‚úÖ Docker + Dockerfile ready
- ‚úÖ pytest + pytest-asyncio configured
- ‚úÖ Railway deployment docs

**Database (Prisma Schema):**
- ‚úÖ PostgreSQL via Prisma
- ‚úÖ Models:
  - `User` (Clerk integration via clerkId)
  - `Document` (file uploads with Vercel Blob URLs)
  - `PipelineRun` (innovation analysis tracking)
  - `OpportunityCard` (generated innovation cards)
  - `InspirationReport` (full reports)
  - `StageOutput` (pipeline stage outputs)
- ‚úÖ Migrations ready
- ‚úÖ Seed scripts (tsx prisma/seed.ts)

**Deployment Infrastructure:**
- ‚úÖ Vercel deployment guide (`innovation-web/VERCEL-DEPLOYMENT.md`)
- ‚úÖ Railway deployment guide (`backend/DEPLOYMENT.md`)
- ‚úÖ Prisma deployment guide (`innovation-web/PRISMA-SETUP.md`)
- ‚úÖ Environment variables documented

**Manquant (facilement ajoutables):**
- ‚ùå Stripe integration (paiements) - Effort: 2-3h
- ‚ö†Ô∏è Railway database provisionn√© (n√©cessite compte Railway)

---

## üìπ Mapping D√©taill√©: 20 Sujets Vid√©o

### ‚úÖ **APPLICABLES IMM√âDIATEMENT** (16 sujets)

---

#### **Sujet 1: FastAPI MCP - Debugger son application**

**Statut:** ‚úÖ **EXCELLENT MATCH**

**Ce qu'il y a:**
- Backend FastAPI complet dans `backend/app/`
- Endpoints API pour pipeline, documents, users
- Pipeline LangChain multi-stages int√©gr√©

**Application:**
Debugger le backend FastAPI qui traite des documents et g√©n√®re des innovations via LangChain.

**D√©mo (2-3 min):**
1. **[0:00-0:30]** Montrer l'app qui tourne: backend FastAPI + frontend Next.js
2. **[0:30-1:00]** Probl√®me: endpoint `/api/pipeline/run` retourne erreur 500
3. **[1:00-1:45]** Ouvrir Claude Code avec FastAPI MCP:
   - "Qu'est-ce qui ne va pas avec /api/pipeline/run?"
   - Claude inspecte endpoint, teste requ√™te, lit logs
4. **[1:45-2:15]** Claude identifie: validation Pydantic manquante sur `companyName`
5. **[2:15-2:45]** Fix appliqu√©, re-test via FastAPI MCP ‚Üí ‚úÖ fonctionne
6. **[2:45-3:00]** Commentaire: "Debugger FastAPI sans quitter Claude"

**Fichiers concern√©s:**
- `backend/app/main.py` - FastAPI application
- `backend/app/routes/` - API routes (pipeline, documents, users)
- `backend/pipeline/` - LangChain pipeline stages

---

#### **Sujet 2: Serena MCP - √âconomiser des tokens intelligemment**

**Statut:** ‚úÖ **PARFAIT MATCH**

**Ce qu'il y a:**
- Pipeline LangChain avec multiples appels LLM (5 stages)
- Prompts volumineux dans `backend/pipeline/prompts/`
- Documentation research massive (24 docs, 60K+ mots)

**Application:**
Optimiser les appels LLM du pipeline d'analyse innovation pour r√©duire co√ªts de 40-60%.

**D√©mo (2-3 min):**
1. **[0:00-0:30]** Lancer analyse innovation SANS Serena:
   - Upload PDF ‚Üí Pipeline 5 stages ‚Üí Afficher token count total
   - Exemple: "45,000 tokens consomm√©s"
2. **[0:30-1:00]** Activer Serena MCP dans Claude Code
3. **[1:00-1:45]** Relancer m√™me analyse AVEC Serena:
   - Serena optimise contexte envoy√© √† chaque stage
   - R√©sume docs research au lieu de tout envoyer
4. **[1:45-2:15]** R√©sultat: "18,000 tokens consomm√©s" (60% √©conomie)
5. **[2:15-2:45]** Comparaison qualit√©: outputs identiques
6. **[2:45-3:00]** Calcul ROI: "$450/mois ‚Üí $180/mois"

**Fichiers concern√©s:**
- `backend/pipeline/stages/` - 5 pipeline stages (chacun appelle LLM)
- `backend/pipeline/prompts/` - Prompt templates
- `documentation/` - Research docs (context √† optimiser)

---

#### **Sujet 3: Vercel & Railway MCP - D√©ployer sans √™tre DevOps**

**Statut:** ‚úÖ **DEPLOYMENT READY**

**Ce qu'il y a:**
- `innovation-web/VERCEL-DEPLOYMENT.md` (guide complet)
- `backend/DEPLOYMENT.md` (Railway + Docker)
- `innovation-web/PRISMA-SETUP.md` (database setup)
- Dockerfile pr√™t dans `backend/`

**Application:**
D√©ployer l'app innovation compl√®te (frontend + backend + DB) en moins de 5 minutes.

**D√©mo (4-5 min):**
1. **[0:00-0:30]** App tourne en local: localhost:3000 (frontend) + localhost:8000 (backend)
2. **[0:30-1:15]** Claude Code + Vercel MCP: "D√©ploie mon frontend"
   - D√©tecte Next.js 15
   - Configure build automatiquement
   - Deploy ‚Üí URL: `innovation-app.vercel.app`
3. **[1:15-2:30]** Claude Code + Railway MCP: "D√©ploie mon backend FastAPI"
   - Cr√©e service Railway
   - Configure Dockerfile
   - Provisionne PostgreSQL database
   - Variables d'environnement (OpenAI API key, DATABASE_URL)
   - Deploy ‚Üí URL: `backend-production-xyz.up.railway.app`
4. **[2:30-3:15]** Connecter frontend ‚Üî backend:
   - Update `NEXT_PUBLIC_API_URL` dans Vercel
   - Redeploy frontend
5. **[3:15-4:00]** Test complet:
   - Upload PDF sur app live
   - Backend traite via LangChain
   - Affiche r√©sultats
6. **[4:00-4:30]** Prisma migration sur Railway DB:
   - `npx prisma migrate deploy`
   - Database tables cr√©√©es
7. **[4:30-5:00]** Commentaire: "De localhost √† production en 5 minutes"

**Fichiers concern√©s:**
- `innovation-web/VERCEL-DEPLOYMENT.md`
- `backend/DEPLOYMENT.md`
- `backend/Dockerfile`
- `innovation-web/prisma/schema.prisma`

---

#### **Sujet 4: Playwright MCP - Tester automatiquement**

**Statut:** ‚úÖ **APPLICATION TESTABLE**

**Ce qu'il y a:**
- Frontend Next.js avec UI compl√®te
- Flow utilisateur: Login (Clerk) ‚Üí Upload PDF ‚Üí View Results
- Components testables (`innovation-web/components/`)

**Application:**
Tester automatiquement le workflow complet d'analyse innovation avec Playwright.

**D√©mo (3-4 min):**
1. **[0:00-0:30]** Montrer le flow utilisateur manuellement:
   - Connexion Clerk
   - Upload PDF "savannah-bananas.pdf"
   - Wait for analysis (5 stages)
   - View opportunity cards
2. **[0:30-1:15]** Dans Claude: "Teste ce flow automatiquement avec Playwright"
3. **[1:15-2:30]** Claude via Playwright MCP:
   - Lance navigateur (visible)
   - Navigue vers app
   - Clerk auto-login (test user)
   - Upload file via dropzone
   - Wait for progress indicator (5 stages)
   - V√©rifie que 5-7 opportunity cards apparaissent
4. **[2:30-3:00]** Screenshot de chaque √©tape sauvegard√©
5. **[3:00-3:30]** Introduire bug: supprimer bouton upload
6. **[3:30-4:00]** Re-run test ‚Üí √âchec, Claude identifie o√π
7. **[4:00-4:20]** Commentaire: "Testing E2E sans √©crire de code"

**Fichiers concern√©s:**
- `innovation-web/app/` - Pages Next.js
- `innovation-web/components/` - UI components (upload, cards, etc.)
- `innovation-web/middleware.ts` - Clerk auth middleware

---

#### **Sujet 5: Sub-agents - D√©l√©guer la lecture, garder le contr√¥le**

**Statut:** ‚úÖ **EXCELLENT MATCH**

**Ce qu'il y a:**
- Documentation massive: 24 research docs (60K+ mots)
- Research domains: `research/`, `psychology/`, `agent-personas/`, `workflow-design/`
- Pipeline complexe n√©cessitant contexte research

**Application:**
Sub-agent lit toute la documentation research, r√©sume pour l'agent principal qui impl√©mente feature.

**D√©mo (3-4 min):**
1. **[0:00-0:45]** T√¢che: "Ajoute un 6e stage au pipeline bas√© sur biomimicry research"
2. **[0:45-1:15]** **Mauvaise approche** (sans sub-agent):
   - Agent principal lit tous les docs research
   - Token count: 55,000 tokens
   - Perd le fil, r√©sultat m√©diocre
3. **[1:15-2:00]** **Bonne approche** (avec sub-agent):
   - "Lance un sub-agent pour analyser la documentation biomimicry"
4. **[2:00-3:00]** Sub-agent:
   - Lit `research/sit-systematic-inventive-thinking.md`
   - Lit `agent-personas/nature-translator.md`
   - Analyse patterns biomimicry
   - Produit r√©sum√© 2 pages: "Voici comment int√©grer biomimicry au pipeline"
5. **[3:00-3:45]** Agent principal:
   - Re√ßoit r√©sum√© concis (2K tokens)
   - Impl√©mente nouveau stage bas√© sur r√©sum√©
   - Code pr√©cis, bien structur√©
6. **[3:45-4:15]** Comparaison:
   - Sans sub-agent: 55K tokens, r√©sultat moyen
   - Avec sub-agent: 8K tokens total, r√©sultat excellent
7. **[4:15-4:30]** Commentaire: "D√©l√©gation = efficacit√©"

**Fichiers concern√©s:**
- `research/` (9 docs: TRIZ, SIT, biomimicry, neuroscience)
- `psychology/` (4 docs: SPECTRE framework, validation)
- `agent-personas/` (7 docs: 6 agent personalities)
- `backend/pipeline/stages/` (√† √©tendre avec nouveau stage)

---

#### **Sujet 6: Loop & V√©rification - D√©velopper des syst√®mes robustes**

**Statut:** ‚úÖ **PARFAIT CANDIDAT**

**Ce qu'il y a:**
- Pipeline 5 stages s√©quentiels
- Validation framework SPECTRE d√©fini dans research
- Tests pytest configur√©s (`backend/pytest.ini`)

**Application:**
Ajouter boucles de v√©rification apr√®s chaque stage du pipeline pour maintenir qualit√©.

**D√©mo (4-5 min):**
1. **[0:00-0:45]** **Sans v√©rification** (approach actuelle):
   - Pipeline run complet
   - Stage 3 g√©n√®re output de mauvaise qualit√©
   - Stages 4-5 construisent sur mauvaises bases
   - R√©sultat final: m√©diocre
2. **[0:45-1:30]** Ajouter loop verification au Stage 1:
   - "Impl√©mente verification loop pour Stage 1"
   - Claude ajoute:
     ```python
     # Stage 1: Pattern Recognition
     output = run_stage_1(input)

     # Verification loop
     quality_score = verify_output(output, quality_criteria)
     if quality_score < 0.8:
         output = correct_and_retry(output, feedback)
     ```
3. **[1:30-2:30]** D√©finir crit√®res de qualit√©:
   - Output doit contenir 5-7 patterns minimum
   - Chaque pattern doit avoir score de confiance >0.7
   - Format YAML valide
4. **[2:30-3:30]** Appliquer √† tous les 5 stages:
   - Stage 2: Validation SPECTRE framework
   - Stage 3: Market psychology check
   - Stage 4: Technical feasibility
   - Stage 5: Final synthesis quality
5. **[3:30-4:15]** Re-run pipeline avec verification loops:
   - Stage 3 √©choue verification
   - Claude corrige automatiquement
   - Re-v√©rifie ‚Üí passe
   - Stages 4-5 construisent sur bonnes bases
6. **[4:15-4:45]** R√©sultat: Quality score 9.2/10 vs 6.5/10
7. **[4:45-5:00]** Commentaire: "Plus lent maintenant, plus rapide sur le long terme"

**Fichiers concern√©s:**
- `backend/pipeline/stages/stage_1_pattern_recognition.py`
- `backend/pipeline/stages/stage_2_validation.py`
- `backend/pipeline/stages/stage_3_market_analysis.py`
- `backend/pipeline/stages/stage_4_technical_feasibility.py`
- `backend/pipeline/stages/stage_5_synthesis.py`
- `psychology/spectre-validation-framework.md`
- `backend/tests/` (ajouter tests de verification)

---

#### **Sujet 7: La Stack Moderne - Vue d'ensemble**

**Statut:** ‚úÖ **STACK COMPL√àTE D√âJ√Ä EN PLACE**

**Ce qu'il y a:**
- ‚úÖ Vercel (frontend Next.js)
- ‚úÖ Railway (backend FastAPI + PostgreSQL)
- ‚úÖ Prisma (ORM + migrations)
- ‚úÖ Clerk (auth)
- ‚úÖ NeonDB compatible (PostgreSQL)
- ‚ùå Stripe (√† ajouter - 2h effort)

**Application:**
Pr√©senter la stack compl√®te et montrer comment chaque pi√®ce s'int√®gre.

**D√©mo (5-6 min):**
1. **[0:00-1:00]** Vue d'ensemble - Diagramme de la stack:
   ```
   [User Browser]
        ‚Üì
   [Vercel - Next.js Frontend]
        ‚Üì (Auth)
   [Clerk Authentication]
        ‚Üì (API calls)
   [Railway - FastAPI Backend]
        ‚Üì (ORM)
   [Prisma Client]
        ‚Üì (SQL)
   [Railway PostgreSQL Database]
   ```

2. **[1:00-2:00]** **Layer 1: Database (Prisma + Railway PostgreSQL)**
   - Montrer schema.prisma
   - Run migration: `npx prisma migrate dev`
   - Open Prisma Studio: visualiser tables
   - Insert seed data

3. **[2:00-3:15]** **Layer 2: Backend (FastAPI + Railway)**
   - Montrer endpoints API (`backend/app/routes/`)
   - Test endpoint: `POST /api/pipeline/run`
   - Backend query DB via Prisma
   - Process document via LangChain
   - Return results

4. **[3:15-4:30]** **Layer 3: Frontend (Next.js + Vercel)**
   - Montrer pages (`innovation-web/app/`)
   - Upload component calls backend API
   - Results affich√©s via shadcn/ui components
   - Dark mode toggle (next-themes)

5. **[4:30-5:15]** **Layer 4: Auth (Clerk)**
   - Montrer middleware.ts (protected routes)
   - Login flow: Clerk modal
   - User sync Clerk ‚Üí Prisma DB
   - User documents & pipeline runs

6. **[5:15-5:45]** **Layer 5: Storage (Vercel Blob)**
   - Upload PDF ‚Üí Vercel Blob
   - Get signed URL
   - Backend download from Blob URL
   - Process avec LangChain

7. **[5:45-6:00]** Commentaire: "Stack moderne, assembl√©e et fonctionnelle"

**Fichiers concern√©s:**
- `innovation-web/prisma/schema.prisma`
- `backend/app/main.py`
- `innovation-web/app/` (pages)
- `innovation-web/middleware.ts` (Clerk)
- `innovation-web/app/api/upload/route.ts` (Vercel Blob)

---

#### **Sujet 8: Prisma MCP - Cr√©er et migrer des bases de donn√©es**

**Statut:** ‚úÖ **PRISMA FULLY CONFIGURED**

**Ce qu'il y a:**
- Schema Prisma complet (6 models)
- Migrations configured
- Seed script ready (`prisma/seed.ts`)
- Railway PostgreSQL integration docs

**Application:**
Montrer comment cr√©er et modifier le sch√©ma DB, migrer, et visualiser avec Prisma Studio.

**D√©mo (4-5 min):**
1. **[0:00-0:30]** Partir de schema existant (6 models)
2. **[0:30-1:15]** Besoin: "J'ai besoin d'ajouter un syst√®me de favoris pour les OpportunityCards"
3. **[1:15-2:00]** Claude + Prisma MCP:
   - Analyse schema actuel
   - Propose modification:
     ```prisma
     model OpportunityCard {
       // ... existing fields
       isStarred Boolean @default(false)  // NOUVEAU

       @@index([isStarred])  // NOUVEAU index
     }
     ```
4. **[2:00-2:30]** Cr√©er migration:
   - Claude: `npx prisma migrate dev --name add-starred-cards`
   - Migration SQL g√©n√©r√©e automatiquement
5. **[2:30-3:00]** Appliquer sur Railway:
   - Claude: `npx prisma migrate deploy`
   - Database mise √† jour sans downtime
6. **[3:00-3:45]** Ouvrir Prisma Studio:
   - `npx prisma studio`
   - Visualiser OpportunityCards table
   - Voir nouveau champ `isStarred`
   - Modifier donn√©es visuellement
7. **[3:45-4:15]** Ajouter donn√©es via seed:
   - Modifier `prisma/seed.ts`
   - `npm run prisma:seed`
   - 50 opportunity cards cr√©√©es avec isStarred randomis√©
8. **[4:15-4:45]** Utiliser dans app:
   - Frontend: ajouter star icon
   - API route: toggle isStarred
   - Query: `where: { isStarred: true }`
9. **[4:45-5:00]** Commentaire: "De l'id√©e de donn√©es √† la feature compl√®te en 5 minutes"

**Fichiers concern√©s:**
- `innovation-web/prisma/schema.prisma`
- `innovation-web/prisma/migrations/`
- `innovation-web/prisma/seed.ts`
- `innovation-web/PRISMA-SETUP.md`

---

#### **Sujet 9: Context7 MCP - Documentation toujours √† jour**

**Statut:** ‚úÖ **APPLICABLE**

**Ce qu'il y a:**
- Next.js 15.5.6 (version tr√®s r√©cente)
- React 19.1.0 (version cutting-edge)
- Prisma 6.18.0 (derni√®re version)
- LangChain 1.0+ (API chang√©e)

**Application:**
Utiliser Context7 pour acc√©der docs officielles latest versions lors de l'ajout de features.

**D√©mo (3-4 min):**
1. **[0:00-0:30]** Besoin: "Utilise les nouveaux React 19 hooks (use, useActionState)"
2. **[0:30-1:00]** **Sans Context7:**
   - Chercher Google "react 19 hooks"
   - Trouver article de 2023 (React 18)
   - Code ne fonctionne pas (API chang√©e)
3. **[1:00-1:45]** **Avec Context7:**
   - Activer Context7 MCP
   - "Utilise React 19 use hook pour data fetching"
   - Context7 ‚Üí docs React 19 officielles
4. **[1:45-2:30]** Claude g√©n√®re code correct:
   ```tsx
   import { use } from 'react';

   function Component({ dataPromise }) {
     const data = use(dataPromise);  // React 19 feature
     return <div>{data}</div>;
   }
   ```
5. **[2:30-3:00]** Autre exemple: "Utilise Next.js 15 partial prerendering"
6. **[3:00-3:30]** Context7 ‚Üí Next.js 15 docs
7. **[3:30-3:50]** Code g√©n√©r√© avec config correcte
8. **[3:50-4:00]** Commentaire: "Toujours la derni√®re doc, z√©ro friction"

**Fichiers concern√©s:**
- `innovation-web/package.json` (d√©pendances latest)
- `innovation-web/app/` (pages avec features modernes)
- `innovation-web/next.config.ts`

---

#### **Sujet 10: GitHub MCP - Code review automatis√©**

**Statut:** ‚úÖ **REPO GITHUB ACTIF**

**Ce qu'il y a:**
- Repo GitHub public
- Branche `architecture-cleanup-prisma` active
- Code Python + TypeScript √† reviewer

**Application:**
Review automatique d'un commit qui ajoute une feature au pipeline.

**D√©mo (4-5 min):**
1. **[0:00-0:30]** Commit r√©cent: "Add Stage 6 - Strategic Foresight"
2. **[0:30-1:00]** Dans Claude: "Review mon dernier commit via GitHub"
3. **[1:00-2:15]** Claude via GitHub MCP:
   - Fetch commit diff
   - Analyse changements:
     - Nouveau fichier: `backend/pipeline/stages/stage_6_foresight.py`
     - Modifi√©: `backend/app/routes/pipeline.py`
     - Modifi√©: `innovation-web/prisma/schema.prisma`
4. **[2:15-3:15]** Feedback d√©taill√©:
   - ‚úÖ Good: Stage suit pattern des autres stages
   - ‚ö†Ô∏è Warning: Manque tests pour nouveau stage
   - ‚ùå Issue: Schema Prisma manque migration
   - üí° Suggestion: Ajouter rate limiting (OpenAI API)
   - üîí Security: API key expos√©e dans code (move to .env)
5. **[3:15-4:00]** "Cr√©e une PR avec tes corrections"
6. **[4:00-4:30]** Claude:
   - Cr√©e branche `fix/stage-6-improvements`
   - Applique corrections
   - Ajoute tests pytest
   - Cr√©e migration Prisma
   - Move API key to .env
   - Ouvre PR avec description d√©taill√©e
7. **[4:30-5:00]** Montrer PR sur GitHub: propre, test√©e, s√©curis√©e
8. **[5:00-5:15]** Commentaire: "Review de niveau senior, automatis√©"

**Fichiers concern√©s:**
- `backend/pipeline/stages/`
- `backend/tests/`
- `innovation-web/prisma/`

---

#### **Sujet 11: Clerk MCP - Authentication en 10 minutes**

**Statut:** ‚úÖ **CLERK D√âJ√Ä INT√âGR√â**

**Ce qu'il y a:**
- Clerk v6.33.7 configur√©
- Middleware protection (`innovation-web/middleware.ts`)
- User sync Clerk ‚Üî Prisma
- Protected routes

**Application:**
Montrer comment Clerk est configur√© et comment ajouter protection √† nouvelle route.

**D√©mo (3-4 min):**
1. **[0:00-0:30]** App actuelle: login via Clerk fonctionne
2. **[0:30-1:00]** Montrer middleware.ts:
   ```ts
   export default clerkMiddleware((auth, req) => {
     if (isProtectedRoute(req)) auth.protect();
   });
   ```
3. **[1:00-1:45]** Cr√©er nouvelle page: `/innovation-web/app/admin/page.tsx`
4. **[1:45-2:15]** "Prot√®ge cette page admin avec Clerk"
5. **[2:15-2:45]** Claude ajoute:
   ```ts
   // middleware.ts
   const protectedRoutes = [
     '/dashboard',
     '/upload',
     '/admin'  // NOUVEAU
   ];
   ```
6. **[2:45-3:15]** Test:
   - Naviguer vers /admin sans login ‚Üí Redirect vers Clerk
   - Login ‚Üí Acc√®s granted
7. **[3:15-3:45]** Bonus: User role-based access
   - "Limite /admin aux users avec role='admin'"
   - Claude ajoute check sur `session.user.role`
8. **[3:45-4:00]** Commentaire: "S√©curit√© production-grade en minutes"

**Fichiers concern√©s:**
- `innovation-web/middleware.ts`
- `innovation-web/app/layout.tsx` (ClerkProvider)
- `innovation-web/lib/auth.ts`

---

#### **Sujet 14: Custom Instructions - Agent personnalis√©**

**Statut:** ‚úÖ **CLAUDE.MD D√âJ√Ä COMPLET**

**Ce qu'il y a:**
- `CLAUDE.md` racine du repo (22KB)
- `innovation-web/CLAUDE.md` (6KB)
- Context complet sur le projet

**Application:**
Montrer comment CLAUDE.md configure Claude pour conna√Ætre le projet.

**D√©mo (2-3 min):**
1. **[0:00-0:30]** Probl√®me: nouveau dev joint le projet, ne conna√Æt rien
2. **[0:30-1:00]** Sans CLAUDE.md:
   - "Ajoute un endpoint API"
   - Claude g√©n√®re code generic, pas adapt√© au projet
3. **[1:00-1:45]** Avec CLAUDE.md:
   - Claude lit automatiquement CLAUDE.md au d√©marrage
   - Comprend:
     - Stack: Next.js 15 + FastAPI + Prisma + Clerk
     - Architecture: innovation pipeline 5 stages
     - Conventions: TypeScript strict, Prisma ORM
     - BMAD framework integration
4. **[1:45-2:15]** "Ajoute un endpoint API pour exporter results en PDF"
5. **[2:15-2:45]** Claude g√©n√®re code parfaitement adapt√©:
   - FastAPI route dans bon dossier
   - Utilise Prisma pour query
   - Suit conventions projet
   - Ajoute auth Clerk check
   - G√©n√®re PDF avec jsPDF (d√©j√† dans package.json)
6. **[2:45-3:00]** Commentaire: "Claude conna√Æt VOTRE projet"

**Fichiers concern√©s:**
- `CLAUDE.md` (racine)
- `innovation-web/CLAUDE.md`

---

#### **Sujet 15: Memory & Context Management - Projets complexes**

**Statut:** ‚úÖ **PROJET COMPLEXE ID√âAL**

**Ce qu'il y a:**
- Monorepo avec frontend + backend
- 24 research docs
- Multiple syst√®mes (auth, DB, pipeline, storage)

**Application:**
Cr√©er structure `.context/` pour documenter d√©cisions architecturales.

**D√©mo (4-5 min):**
1. **[0:00-0:45]** Projet complexe: Claude se perd apr√®s 10 conversations
2. **[0:45-1:30]** "Cr√©e une structure .context/ pour documenter d√©cisions"
3. **[1:30-2:30]** Claude cr√©e:
   ```
   .context/
     decisions/
       ADR-001-why-clerk-over-nextauth.md
       ADR-002-why-fastapi-not-nextjs-api.md
       ADR-003-prisma-over-raw-sql.md
       ADR-004-langchain-version-pinned.md
     architecture/
       system-overview.md
       data-flow-diagram.md
       deployment-architecture.md
     conventions/
       code-style.md
       commit-messages.md
       api-patterns.md
   ```
4. **[2:30-3:15]** Documenter ADR-001:
   ```markdown
   # ADR-001: Why Clerk over NextAuth

   Date: 2024-01-15
   Status: Accepted

   ## Context
   Need authentication for innovation app with user management.

   ## Decision
   Use Clerk instead of NextAuth.

   ## Rationale
   - Built-in user management UI
   - Easier webhook integration
   - Better TypeScript support
   - Less code to maintain

   ## Consequences
   - Paid service ($25/mo)
   - Vendor lock-in (mitigated by standard OAuth)
   - Faster development
   ```
5. **[3:15-4:00]** 3 semaines plus tard:
   - "Pourquoi on utilise Clerk?"
   - Claude lit `.context/decisions/ADR-001-*.md`
   - R√©pond avec contexte exact
6. **[4:00-4:30]** "Devrait-on migrer vers NextAuth?"
7. **[4:30-4:50]** Claude analyse ADR, r√©pond avec raisons document√©es
8. **[4:50-5:00]** Commentaire: "M√©moire persistante = projets scalables"

**Fichiers √† cr√©er:**
- `.context/` structure compl√®te

---

#### **Sujet 16: Diagnostic Brownfield - Documenter projet existant**

**Statut:** ‚úÖ **PROJET PARFAIT POUR DIAGNOSTIC**

**Ce qu'il y a:**
- Projet existant complexe
- Architecture multi-tier
- Multiple technologies

**Application:**
Analyst agent documente le projet complet pour nouveau dev.

**D√©mo (5-6 min):**
1. **[0:00-0:30]** Nouveau dev arrive, projet myst√®re
2. **[0:30-1:00]** Activer `/BMad:agents:analyst`
3. **[1:00-1:30]** Analyst: `*document-project`
4. **[1:30-3:30]** Agent analyse:
   - Scan `innovation-web/` ‚Üí Next.js 15, Clerk, Prisma
   - Scan `backend/` ‚Üí FastAPI, LangChain pipeline
   - Scan `prisma/schema.prisma` ‚Üí 6 models, relations
   - Scan research docs ‚Üí Innovation intelligence domain
   - Scan deployment docs ‚Üí Vercel + Railway

5. **[3:30-5:00]** G√©n√®re rapport structur√©:
   ```markdown
   # Innovation Intelligence System - Project Analysis

   ## Tech Stack
   - Frontend: Next.js 15.5.6 + React 19 + TypeScript
   - Backend: FastAPI 0.115.0 + Python 3.10+
   - Database: PostgreSQL via Prisma 6.18.0
   - Auth: Clerk 6.33.7
   - Storage: Vercel Blob
   - AI: LangChain 1.0 + OpenAI

   ## Architecture
   - Monorepo structure (frontend + backend)
   - 5-stage innovation pipeline
   - User uploads documents ‚Üí Pipeline analyzes ‚Üí Generates opportunity cards

   ## Database Schema
   - User (Clerk sync)
   - Document (uploaded PDFs)
   - PipelineRun (analysis sessions)
   - OpportunityCard (generated innovations)
   - InspirationReport (full reports)

   ## Key Workflows
   1. User uploads PDF via Vercel Blob
   2. Backend fetches from Blob URL
   3. LangChain pipeline (5 stages)
   4. Results saved to PostgreSQL
   5. Frontend displays opportunity cards

   ## Technical Debt
   - ‚ö†Ô∏è No Stripe integration (payments needed)
   - ‚ö†Ô∏è Limited error handling in pipeline
   - ‚ö†Ô∏è No retry logic for LLM failures

   ## Deployment
   - Frontend: Vercel
   - Backend: Railway + PostgreSQL
   - Environment: 15+ env variables
   ```

6. **[5:00-5:45]** "Comment j'ajoute un nouveau pipeline stage?"
7. **[5:45-6:00]** Analyst utilise diagnostic, donne plan pr√©cis

**Fichiers concern√©s:**
- Tout le repo (scan complet)
- Output: `docs/project-diagnostic.md`

---

#### **Sujet 17: TDD - Tests avant code**

**Statut:** ‚úÖ **TESTS CONFIGUR√âS**

**Ce qu'il y a:**
- Jest configur√© (`innovation-web/jest.config.js`)
- pytest configur√© (`backend/pytest.ini`)
- Testing Library installed

**Application:**
Ajouter une feature avec TDD: tests d'abord, code ensuite.

**D√©mo (5-6 min):**
1. **[0:00-0:30]** Feature: "Syst√®me de tags pour OpportunityCards"
2. **[0:30-1:30]** **Phase RED** - √âcrire tests d'abord:
   - "Claude, √©cris les tests pour le syst√®me de tags"
   - Tests backend (pytest):
     ```python
     def test_add_tag_to_card():
         card = create_opportunity_card()
         result = add_tag(card.id, "biomimicry")
         assert "biomimicry" in result.tags

     def test_filter_cards_by_tag():
         cards = filter_by_tag("TRIZ")
         assert all("TRIZ" in c.tags for c in cards)
     ```
   - Tests frontend (Jest):
     ```tsx
     it('displays tags on card', () => {
       render(<OpportunityCard tags={['biomimicry', 'TRIZ']} />)
       expect(screen.getByText('biomimicry')).toBeInTheDocument()
     })
     ```

3. **[1:30-2:00]** Run tests: ‚ùå TOUS √©chouent (normal, pas de code encore)

4. **[2:00-3:30]** **Phase GREEN** - Impl√©menter code:
   - Modifier Prisma schema:
     ```prisma
     model OpportunityCard {
       // ... existing
       tags String[]  // NOUVEAU
     }
     ```
   - Migration: `npx prisma migrate dev`
   - Backend API:
     ```python
     @router.post("/{card_id}/tags")
     async def add_tag(card_id: str, tag: str):
         card = await db.opportunitycard.update(
             where={"id": card_id},
             data={"tags": {"push": tag}}
         )
         return card
     ```
   - Frontend component:
     ```tsx
     <div className="tags">
       {tags.map(tag => <Badge key={tag}>{tag}</Badge>)}
     </div>
     ```

5. **[3:30-4:00]** Re-run tests: ‚úÖ TOUS passent

6. **[4:00-5:00]** **Phase REFACTOR**:
   - "Optimise le code sans casser tests"
   - Claude refactorise:
     - Extrait TagBadge component
     - Ajoute index DB sur tags
     - Cache tag queries
   - Re-run tests: ‚úÖ toujours passent

7. **[5:00-5:45]** Ajouter edge cases:
   - Test: duplicate tags
   - Test: empty tag string
   - Claude ajout validation

8. **[5:45-6:00]** Commentaire: "TDD = confiance que √ßa marche"

**Fichiers concern√©s:**
- `innovation-web/__tests__/`
- `backend/tests/`
- `innovation-web/prisma/schema.prisma`
- `backend/app/routes/cards.py`
- `innovation-web/components/opportunity-card.tsx`

---

#### **Sujet 18: Refactoring automatis√© - Dette technique**

**Statut:** ‚úÖ **CODE √Ä REFACTORER PR√âSENT**

**Ce qu'il y a:**
- Pipeline code complexe
- Some legacy patterns
- Opportunities for improvement

**Application:**
Refactorer code pipeline en maintenant tests.

**D√©mo (4-5 min):**
1. **[0:00-0:45]** Identifier code messy:
   - `backend/pipeline/stages/stage_3_market_analysis.py` (200 lignes)
   - Fonction monolithique
   - Variables mal nomm√©es (`temp_var1`, `result2`)
   - Duplication de code
2. **[0:45-1:15]** Run tests actuels: ‚úÖ 15 tests passent
3. **[1:15-2:00]** "Claude, analyse ce fichier et identifie probl√®mes"
   - Complexity: 45 (tr√®s √©lev√©)
   - Code duplication: 35%
   - Poor naming: 12 variables
   - Missing docstrings
4. **[2:00-3:00]** "Refactorise en gardant tests verts"
   - Extrait 4 fonctions:
     - `extract_market_signals()`
     - `analyze_adoption_psychology()`
     - `generate_insights()`
     - `format_output()`
   - Renomme variables
   - Ajoute type hints
   - Docstrings
5. **[3:00-3:30]** R√©sultat:
   ```python
   # Avant: 200 lignes, complexity 45
   def run_stage_3(input_data):
       temp_var1 = ...
       result2 = ...
       # 180 lignes de logique imbriqu√©e

   # Apr√®s: 80 lignes, complexity 12
   def run_stage_3(input_data: StageInput) -> StageOutput:
       """Analyze market adoption psychology."""
       signals = extract_market_signals(input_data)
       psychology = analyze_adoption_psychology(signals)
       insights = generate_insights(psychology)
       return format_output(insights)
   ```
6. **[3:30-4:00]** Re-run tests: ‚úÖ 15 tests toujours passent
7. **[4:00-4:30]** Metrics:
   - Avant: 200 lignes, complexity 45
   - Apr√®s: 80 lignes, complexity 12
   - Tests: ‚úÖ Identiques
8. **[4:30-4:45]** Commentaire: "Code propre sans casser fonctionnalit√©"

**Fichiers concern√©s:**
- `backend/pipeline/stages/stage_3_market_analysis.py`
- `backend/tests/test_stage_3.py`

---

#### **Sujet 19: Web Scraping Playwright - Sources de donn√©es**

**Statut:** ‚ö†Ô∏è **USE CASE √Ä D√âFINIR**

**Ce qu'il y a:**
- Pipeline qui analyse documents
- Potentiel pour scraper trend reports

**Application:**
Scraper TrendHunter ou TrendWatching pour alimenter pipeline.

**D√©mo (5-6 min):**
1. **[0:00-0:30]** Besoin: "Alimenter pipeline avec derni√®res tendances TrendHunter"
2. **[0:30-1:00]** V√©rifier robots.txt: "Claude, puis-je scraper trendhunter.com?"
3. **[1:00-2:00]** Claude + Playwright MCP:
   - Navigate vers trendhunter.com/trends
   - Identifie s√©lecteurs CSS
   - Extrait:
     - Trend title
     - Description
     - Category
     - Date published
4. **[2:00-3:00]** Structure donn√©es:
   ```json
   [
     {
       "title": "Sacred Sync - Digital Wellness",
       "description": "Consumers seeking...",
       "category": "Lifestyle",
       "date": "2024-01-15",
       "url": "https://trendhunter.com/trends/sacred-sync"
     }
   ]
   ```
5. **[3:00-4:00]** Sauvegarder dans DB:
   - Nouveau model Prisma: `TrendSource`
   - Import data via seed script
6. **[4:00-5:00]** Int√©grer au pipeline:
   - Stage 1 utilise trend data comme input suppl√©mentaire
   - Am√©liore pattern recognition
7. **[5:00-5:30]** Automatiser:
   - Cron job daily scrape
   - Claude cr√©e GitHub Action
8. **[5:30-6:00]** Disclaimer √©thique: respecte robots.txt, rate limiting

**Fichiers concern√©s:**
- `scripts/scrape-trends.ts` (nouveau)
- `innovation-web/prisma/schema.prisma` (add TrendSource model)
- `.github/workflows/scrape-trends.yml` (automation)

---

#### **Sujet 20: Multi-agent Swarms - D√©l√©gation complexe**

**Statut:** ‚úÖ **AGENT PERSONAS D√âFINIS**

**Ce qu'il y a:**
- 6 agent personas document√©s dans `agent-personas/`
- Pipeline 5 stages (peut √™tre orchestr√© par swarm)

**Application:**
Orchestrer analyse innovation avec swarm de 6 agents sp√©cialis√©s.

**D√©mo (6-7 min):**
1. **[0:00-0:45]** T√¢che complexe: "Analyser innovation Savannah Bananas avec tous les angles"
2. **[0:45-1:30]** Initialiser swarm Claude-Flow:
   ```bash
   /claude-flow swarm init --topology hierarchical --max-agents 6
   ```
3. **[1:30-2:30]** Spawn 6 agents sp√©cialis√©s:
   - **Pattern Hunter** (TRIZ/SIT analysis)
   - **Nature Translator** (Biomimicry)
   - **Market Psychologist** (Adoption psychology)
   - **Adversarial Analyst** (Red team validation)
   - **Strategic Oracle** (Foresight trends)
   - **Synthesis Orchestrator** (Integration)

4. **[2:30-4:30]** D√©l√©gation parall√®le:
   - **Split screen montrant 6 agents**:
     - **Top-left**: Pattern Hunter analyse TRIZ contradictions
     - **Top-center**: Nature Translator cherche analogies nature
     - **Top-right**: Market Psychologist √©value adoption barriers
     - **Bottom-left**: Adversarial Analyst identifie risques
     - **Bottom-center**: Strategic Oracle projette 5-year trends
     - **Bottom-right**: Synthesis Orchestrator coordonne

5. **[4:30-5:30]** Chaque agent produit output:
   - Pattern Hunter: "5 TRIZ principles applicables"
   - Nature Translator: "3 biomimicry analogies (ant colonies, mycorrhizal networks)"
   - Market Psychologist: "User adoption score: 8.2/10"
   - Adversarial Analyst: "7 critical risks identified"
   - Strategic Oracle: "Trend alignment: 92%"

6. **[5:30-6:30]** Synthesis Orchestrator int√®gre:
   - Combine perspectives
   - R√©sout conflits (Pattern Hunter vs Adversarial)
   - G√©n√®re rapport unifi√©
   - Score final: 9.1/10 (vs 7.3/10 single agent)

7. **[6:30-6:50]** Metrics:
   - Temps: 8 min (vs 25 min sequential)
   - Qualit√©: 9.1/10 (vs 7.3/10)
   - Couverture: 6 perspectives (vs 1)

8. **[6:50-7:00]** Commentaire: "Swarms = √©quipe compl√®te en minutes"

**Fichiers concern√©s:**
- `agent-personas/*.md` (6 agent definitions)
- `backend/pipeline/` (orchestr√© par swarm)

---

### ‚ö†Ô∏è **N√âCESSITE AJOUT** (2 sujets)

---

#### **Sujet 12: Stripe - Ajouter paiements**

**Statut:** ‚ùå **MANQUANT - Effort: 2-3h**

**Ce qui manque:**
- Stripe SDK
- Checkout flow
- Webhook handling
- Subscription management

**Effort pour ajouter:**
1. Install Stripe:
   ```bash
   npm install stripe @stripe/stripe-js @stripe/react-stripe-js
   ```
2. Cr√©er routes API:
   - `innovation-web/app/api/stripe/checkout/route.ts`
   - `innovation-web/app/api/stripe/webhook/route.ts`
3. Ajouter Prisma model:
   ```prisma
   model Subscription {
     id String @id @default(uuid())
     userId String
     stripeCustomerId String
     stripePriceId String
     status String
     user User @relation(...)
   }
   ```
4. Frontend:
   - Pricing page
   - Checkout button
   - Success/cancel pages

**D√©mo apr√®s ajout (4-5 min):**
1. Pricing page: Free, Pro ($29/mo), Enterprise ($99/mo)
2. Click "Upgrade to Pro"
3. Stripe Checkout modal
4. Paiement test (4242 4242 4242 4242)
5. Webhook re√ßu ‚Üí Update user subscription in DB
6. User acc√®de features Pro (unlimited pipeline runs)

---

#### **Sujet 13: Hero Demo - Prototype complet en 1 jour**

**Statut:** ‚ö†Ô∏è **PRESQUE COMPLET - Manque Stripe**

**Ce qu'il y a:**
- ‚úÖ Frontend Next.js
- ‚úÖ Backend FastAPI
- ‚úÖ Database Prisma
- ‚úÖ Auth Clerk
- ‚úÖ Storage Vercel Blob
- ‚úÖ Deployment Vercel + Railway
- ‚ùå Stripe (n√©cessaire pour demo "SaaS payant")

**Apr√®s ajout Stripe, d√©mo compl√®te possible (15-20 min):**
- Phase 1: Spec (0-2min)
- Phase 2: Database (2-5min)
- Phase 3: Frontend + Auth (5-9min)
- Phase 4: Deployment (9-12min)
- Phase 5: Paiements (12-15min)
- R√©cap (15-16min)

---

## üéØ Recommandations Finales

### **Tournage Imm√©diat (16 vid√©os pr√™tes):**

**Quick Wins (3-4 min chacun):**
1. ‚úÖ Sujet 2: Serena MCP
2. ‚úÖ Sujet 9: Context7
3. ‚úÖ Sujet 10: GitHub Review
4. ‚úÖ Sujet 11: Clerk Auth
5. ‚úÖ Sujet 14: Custom Instructions

**Stack & M√©thodologie (4-6 min chacun):**
6. ‚úÖ Sujet 1: FastAPI Debug
7. ‚úÖ Sujet 3: Vercel/Railway Deploy
8. ‚úÖ Sujet 6: Loop & V√©rification
9. ‚úÖ Sujet 7: Stack compl√®te
10. ‚úÖ Sujet 8: Prisma DB

**Avanc√© (5-7 min chacun):**
11. ‚úÖ Sujet 4: Playwright Testing
12. ‚úÖ Sujet 5: Sub-agents
13. ‚úÖ Sujet 15: Memory Management
14. ‚úÖ Sujet 16: Diagnostic Brownfield
15. ‚úÖ Sujet 17: TDD
16. ‚úÖ Sujet 18: Refactoring
17. ‚úÖ Sujet 20: Swarms

**Use Case Sp√©cifique (optionnel):**
18. ‚ö†Ô∏è Sujet 19: Web Scraping

---

### **Ajout Stripe (2-3h dev):**

Ensuite tourner:
19. ‚úÖ Sujet 12: Stripe Payments
20. ‚úÖ Sujet 13: Hero Demo

---

## üöÄ Plan de Production Recommand√©

### **Semaine 1-2: Quick Wins (5 vid√©os)**
Tournez les sujets faciles pour valider workflow et qualit√©.

### **Semaine 3-4: Stack & Deploy (5 vid√©os)**
D√©montrez la stack compl√®te et deployment.

### **Semaine 5-6: M√©thodologie Avanc√©e (6 vid√©os)**
Diff√©renciez-vous avec sub-agents, swarms, TDD.

### **Semaine 7: Ajout Stripe + Hero Demo (2 vid√©os)**
Compl√©tez avec paiements et demo end-to-end.

### **Optionnel: Web Scraping (1 vid√©o)**
Si use case pertinent identifi√©.

---

**TOTAL: 18 vid√©os imm√©diatement + 2 apr√®s Stripe = 20 vid√©os compl√®tes**

üéâ **Repo parfait pour s√©rie vid√©o Newcode!**
